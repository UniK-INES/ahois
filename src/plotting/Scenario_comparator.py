"""
A module for comparing and visualising simulation results from multiple scenarios.

This module provides the `Scenario_comparator` class, which is designed to
load, process, and plot data from different simulation runs and scenarios.
It reads standardised pickle files generated by the simulation model,
aggregates the data (e.g., by averaging across multiple seeds), and
generates a variety of comparison plots using matplotlib.

:Authors:
 - Ivan Digel <ivan.digel@uni-kassel.de>
 - Sascha Holzhauer <sascha.holzhauer@uni-kassel.de>
"""
import matplotlib.pyplot as plt
from matplotlib import ticker
import pandas as pd
import numpy as np
import seaborn as sns
import itertools
import os
import ast
import re
import glob
import math
import yaml
import logging
import hashlib
import plotly.graph_objects as go
from helpers.utils import load_class, get_images_name
from helpers.config import settings, get_output_path
from helpers.i18n import _

try:
    from adjustText import adjust_text
except ImportError:
    settings.eval.use_adjust_text = False
    

logger = logging.getLogger("ahoi.scenariocompare")

def getLabels(labels_sheet, ascending=True):
    """
    Reads and prepares labels from a specified sheet in an Excel file.

    This function loads labels, colours, and other plotting-related information
    from a dedicated Excel file defined in the global settings. It can handle
    language-specific versions of the file and sorts the labels based on an
    'order' column.

    Parameters
    ----------
    labels_sheet : str
        The name of the sheet within the Excel file to read the labels from.
    ascending : bool, optional
        If True (default), the labels are sorted in ascending order based on the 'order' column.

    Returns
    -------
    pandas.DataFrame
        A DataFrame containing the labels and associated metadata, sorted as specified.
    """
    fileext = os.path.splitext(settings.eval.labels_file)
    file = os.path.join(
        fileext[0] + "_" + settings.eval.language[0] + fileext[1]
    )
    if not os.path.exists(file):
        file = settings.eval.labels_file

    labelsdf = pd.read_excel(
        file,
        sheet_name=labels_sheet,
        header=0,
        usecols="A:I",
    )
    labelsdf.replace(float('nan'), None, inplace=True)
    labelsdf.sort_values("order", ascending=ascending, inplace=True)
    return labelsdf

def prepare_data(df, indexname, ascending=True):
    """
    Prepares the simulation data for plotting by applying labels and grouping.

    This function takes a raw DataFrame of simulation results, replaces 
    labels using `getLabels`, and extracts corresponding colours 
    and plot styles (hatches, markers). It then groups
    the data by scenario, run ID, and file prefix to facilitate plotting.

    Parameters
    ----------
    df : pandas.DataFrame
        The DataFrame containing the raw simulation results.
    indexname : str
        The name of the column in `df` that contains the values to be replaced by labels.
    ascending : bool, optional
        The sort order for the labels, passed to `getLabels`. Defaults to True.

    Returns
    -------
    tuple
        A tuple containing:
        - pandas.core.groupby.DataFrameGroupBy: The grouped DataFrame, ready for iteration.
        - list: A list of colors corresponding to the unique labels.
        - list: A list of hatch patterns for plotting.
        - list: A list of marker styles for plotting.
    """
    labelsdf = getLabels(labels_sheet=indexname, ascending=ascending)
    
    df = df.replace(labelsdf["value"].array, labelsdf["label"].array).infer_objects(copy=False)
    colors = labelsdf[labelsdf["label"].isin(df[indexname].unique())]["colour"].tolist()
    hatches = [None if hatch=="None" else hatch for hatch in labelsdf[labelsdf["label"].isin(df[indexname].unique())]["hatch"].tolist()]
    markers = [None if marker=="None" else marker for marker in labelsdf[labelsdf["label"].isin(df[indexname].unique())]["marker"].tolist()]
    
    # TODO check label is in figure_labels!
    df["order"] = df[indexname].map(
        dict(zip(labelsdf["label"], range(len(labelsdf))))
    ).astype("int")
    return df.groupby(["order","scenario", "run_id", "files_prefix"]), colors, hatches, markers

class Scenario_comparator:
    """
    Used to draw plots that compare different scenarios and runs in a single DataFrame.

    This class automates the process of loading simulation results from multiple
    pickle files, merging them, and generating a suite of comparative plots.
    It handles combinations of different scenarios, run IDs, and file prefixes,
    averaging results across multiple random seeds to provide robust comparisons.
    """

    def __init__(self, scenarios, run_ids, files_prefixes):
        """
        Initialises the comparator and loads all specified simulation data.
        """
        self.scenarios = scenarios
        self.run_ids = run_ids
        self.files_prefixes = files_prefixes

        # 1. Configuration and Path Setup
        self._load_plotting_configuration()
        self._setup_output_paths()

        # 2. Initialize Data Containers
        self._init_dataframes()

        # 3. Load and Process Data (The main loop)
        self._load_all_simulation_data()

        # 4. Finalize Data (Categorization, Grouping, Filtering)
        self._finalize_data_structures()

        # 5. Ensure Output Directory Exists
        if not os.path.exists(self.get_output_folder()):
            os.makedirs(self.get_output_folder())

    # =========================================================================
    # 1. Configuration & Setup Helpers
    # =========================================================================

    def _load_plotting_configuration(self):
        """Loads YAML configuration for matplotlib."""
        with open(settings.data.plt_settings, "r") as configfile:
            config = yaml.safe_load(configfile)
        if "Layout" in config:
            plt.rcParams.update(config["Layout"])
        else:
            raise ValueError("Invalid plotting configuration file: 'Layout' section missing.")

    def _setup_output_paths(self):
        """Generates the folder suffix and output path."""
        self.folder_suffix = "-".join(self.files_prefixes)
        if len(self.folder_suffix) >= 200:
            # Create a hash for very long filenames to avoid OS errors
            hashed_name = hashlib.md5(self.folder_suffix.encode()).hexdigest()[:8]
            self.folder_suffix = f"long_name_{hashed_name}"
        
        base_path = get_output_path(runid=settings.main.run_id, subfolder='plots')
        self.output_folder = f"{base_path}/{self.folder_suffix}"

    def _init_dataframes(self):
        """Initializes the empty DataFrames with expected columns."""
        self.agents_df = pd.DataFrame(columns=[
            "Class", "Suboptimality", "Opex", "Heating", "Emissions", 
            "Energy demand", "scenario", "run_id", "files_prefix"
        ])
        self.models_df = pd.DataFrame(columns=[
            "Scenario fulfilment", "Emissions", "Energy demand", 
            "Known heating systems", "Subsidies", "Loans", "Cognitive resource", 
            "Total expenses", "Heating distribution", "Obstacles",
            "Attribute ratings", "scenario", "run_id", "files_prefix"
        ])
        self.rate_of_change = pd.DataFrame()

    # =========================================================================
    # 2. Main Data Loading Logic
    # =========================================================================

    def _load_all_simulation_data(self):
        """Iterates through all combinations of scenarios, runs, and prefixes."""
        combinations = itertools.product(self.scenarios, self.run_ids, self.files_prefixes)
        
        for scenario, run_id, files_prefix in combinations:
            scenario_id = load_class("Scenario", scenario).id
            pickle_path = get_output_path(runid=run_id, subfolder='pickles')

            # A. Process Model Data
            self._process_model_data(scenario, scenario_id, run_id, files_prefix, pickle_path)

            # B. Process Agent Data (Optional)
            if settings.eval.process_agent_files:
                self._process_agent_data(scenario, scenario_id, run_id, files_prefix, pickle_path)

    def _process_model_data(self, scenario, scenario_id, run_id, files_prefix, pickle_path):
        """Finds, loads, and aggregates model pickle files."""
        pattern = f"{pickle_path}/model_df_{files_prefix}_{scenario_id}_{run_id}_*.pkl"
        model_files = glob.glob(pattern)

        if not model_files:
            print(f"Model files not found for {scenario}, {run_id}, {files_prefix}. Skipping.")
            return

        # Load all seeds
        model_dfs = []
        for file in model_files:
            try:
                df = pd.read_pickle(file)
                # Filter strictly for required columns to save memory
                cols = [
                    "Scenario fulfilment", "Emissions", "Energy demand", 
                    "Known heating systems", "Subsidies", "Loans", "Cognitive resource", 
                    "Total expenses", "Heating distribution", "Obstacles", "Attribute ratings",
                    "Stage flows"
                ]
                model_dfs.append(df[cols])
            except Exception as e:
                print(f"Error reading {file}: {e}")

        if model_dfs:
            # Aggregate across seeds
            aggregated_df = self._aggregate_model_runs(model_dfs, scenario, run_id, files_prefix)
            self.models_df = pd.concat([self.models_df, aggregated_df], ignore_index=True)
        else:
            print(f"No valid model data loaded for {scenario}, {run_id}, {files_prefix}.")

    def _process_agent_data(self, scenario, scenario_id, run_id, files_prefix, pickle_path):
        """Finds and loads agent pickle files."""
        try:
            seeds_sequence = self.get_seeds_from_filename(
                pickle_path, files_prefix, scenario_id, run_id
            )
            agent_filename = f"{pickle_path}/agent_df_{files_prefix}_{scenario_id}_{run_id}_{seeds_sequence}.pkl"
            
            temp_agent_df = pd.read_pickle(agent_filename)
            
            # Select columns and cast types
            cols = ["Class", "Suboptimality", "Opex", "Heating", "Emissions", "Energy demand"]
            temp_agent_df = temp_agent_df[cols]
            temp_agent_df["Heating"] = temp_agent_df["Heating"].astype("category")
            temp_agent_df["Class"] = temp_agent_df["Class"].astype("category")
            
            # Add metadata
            temp_agent_df["scenario"] = scenario
            temp_agent_df["run_id"] = run_id
            temp_agent_df["files_prefix"] = files_prefix

            self.agents_df = pd.concat([self.agents_df, temp_agent_df], ignore_index=False)
        except FileNotFoundError:
            print(f"Agent file for {scenario}, {run_id}, {files_prefix} not found. Skipping.")

    # =========================================================================
    # 3. Aggregation Logic (The Math)
    # =========================================================================

    def _aggregate_model_runs(self, model_dfs, scenario, run_id, files_prefix):
        """Calculates means/stds across multiple seeds for a single scenario."""
        base_df = model_dfs[0].copy()

        # 1. Simple numeric columns (Mean & Std)
        numeric_cols = [
            "Scenario fulfilment", "Emissions", "Energy demand", 
            "Subsidies", "Loans", "Cognitive resource", "Total expenses"
        ]
        
        for col in numeric_cols:
            concat_series = pd.concat([df[col] for df in model_dfs], axis=1)
            base_df[col] = concat_series.mean(axis=1)
            base_df[f"{col} std"] = concat_series.std(axis=1)

        # 2. Complex columns
        base_df["Heating distribution"] = self._compute_heating_distribution(model_dfs)
        base_df["Stage flows"] = self._compute_stage_flows(model_dfs)
        
        ob_avg, ob_std = self._compute_obstacles(model_dfs)
        base_df["Obstacles"] = ob_avg
        # Note: Original code calculated ob_std but only assigned ob_avg to dataframe. 
        # Keeping functionality identical to original.

        # 3. Attribute Ratings (Last step only)
        attr_ratings_list = [df["Attribute ratings"].iloc[-1] for df in model_dfs]
        combined_attr = self.combine_attribute_ratings(attr_ratings_list)
        base_df["Attribute ratings"] = [combined_attr] * len(base_df)

        # 4. Metadata
        base_df["scenario"] = scenario
        base_df["run_id"] = run_id
        base_df["files_prefix"] = files_prefix

        return base_df

    def _compute_heating_distribution(self, model_dfs):
        """Aggregates heating distribution dicts across runs."""
        # Expand list of dicts to list of DataFrames
        hd_expanded = [df["Heating distribution"].apply(pd.Series).fillna(0) for df in model_dfs]
        
        if not hd_expanded:
            return model_dfs[0]["Heating distribution"]

        heating_keys = hd_expanded[0].columns
        hd_avg = pd.DataFrame(index=hd_expanded[0].index)
        
        for key in heating_keys:
            # Concatenate values for this key from all seeds
            hd_values = pd.concat([df[key] for df in hd_expanded], axis=1)
            # Calculate mean and ceil it (as per original logic)
            hd_avg[key] = hd_values.mean(axis=1).apply(math.ceil)
            
        return hd_avg.apply(lambda row: row.to_dict(), axis=1)

    def _compute_stage_flows(self, model_dfs):
        """
        Aggregates 'Stage flows' dictionaries across multiple seeds by averaging their values.
        Returns a list of nested dictionaries (one per time step).
        """
        # Helper to safely parse stringified dicts
        def safe_parse(val):
            if isinstance(val, str):
                return ast.literal_eval(val)
            return val

        # 1. Parse all seeds into a list of lists-of-dicts
        # Structure: all_seeds_data[seed_index][step_index] = { 'Stage_1': ... }
        all_seeds_data = []
        for df in model_dfs:
            if "Stage flows" in df.columns:
                # Convert column from string to dict and store as list
                data = df["Stage flows"].apply(safe_parse).tolist()
                all_seeds_data.append(data)
        
        if not all_seeds_data:
            return []

        # 2. Average the values per step
        n_steps = len(all_seeds_data[0]) 
        num_seeds = len(all_seeds_data)
        averaged_series = []

        # Iterate through every time step (row)
        for step_idx in range(n_steps):
            step_avg = {}
            
            # Get the dicts for this specific step from all seeds
            dicts_at_step = [seed[step_idx] for seed in all_seeds_data]

            # Identify all unique Stages (Stage_1, Stage_2...) present
            all_stages = set().union(*[d.keys() for d in dicts_at_step if isinstance(d, dict)])

            for stage in all_stages:
                step_avg[stage] = {}
                
                # Identify all unique Reasons (Satisfied, Overloaded...) for this stage
                reasons_in_stage = set()
                for d in dicts_at_step:
                    if isinstance(d, dict) and stage in d:
                        reasons_in_stage.update(d[stage].keys())
                
                for reason in reasons_in_stage:
                    # Sum values for this reason across all seeds
                    total_val = 0
                    for d in dicts_at_step:
                        if isinstance(d, dict) and stage in d:
                            total_val += d[stage].get(reason, 0)
                    
                    # Calculate mean
                    step_avg[stage][reason] = total_val / num_seeds
            
            averaged_series.append(step_avg)

        return averaged_series
    
    def _compute_obstacles(self, model_dfs):
        """Aggregates the complex Obstacles time-series data."""
        # Extract full "Obstacles" time series from each run
        all_runs_obstacles = [pd.DataFrame(df["Obstacles"].tolist()) for df in model_dfs]
        
        if not all_runs_obstacles:
            return [], []

        heating_systems = all_runs_obstacles[0].columns
        ob_avg_dict = {}
        ob_std_dict = {}

        # Group by heating system across all runs
        for hs in heating_systems:
            hs_dfs = [pd.DataFrame(run[hs].dropna().tolist()) for run in all_runs_obstacles 
                      if hs in run.columns and not run[hs].dropna().empty]
            
            if not hs_dfs:
                continue

            combined = pd.concat(hs_dfs)
            # Group by index (time step) and aggregate
            ob_avg_dict[hs] = combined.groupby(combined.index).mean().apply(np.ceil)
            ob_std_dict[hs] = combined.groupby(combined.index).std()

        # Reformat from {HS: Series} to [{HS: val, HS: val}, {HS: val...}] (List of dicts per step)
        num_steps = max(len(df) for df in ob_avg_dict.values()) if ob_avg_dict else 0
        avg_list, std_list = [], []

        for i in range(num_steps):
            avg_step, std_step = {}, {}
            for hs, df in ob_avg_dict.items():
                if i < len(df):
                    avg_step[hs] = df.iloc[i].to_dict()
                    if hs in ob_std_dict and i < len(ob_std_dict[hs]):
                        std_step[hs] = ob_std_dict[hs].iloc[i].to_dict()
            avg_list.append(avg_step)
            std_list.append(std_step)
            
        return avg_list, std_list

    # =========================================================================
    # 4. Finalization Logic
    # =========================================================================

    def _finalize_data_structures(self):
        """Performs final categorization, grouping, and filtering."""
        # 1. Prepare Model Data
        if not self.models_df.empty:
            self.models_df["files_prefix"] = pd.Categorical(
                self.models_df["files_prefix"],
                categories=settings.scenario_comparison.files_prefixes,
                ordered=True
            )
            # Apply labels and styles
            self.grouped, self.colors, self.hatches, self.markers = prepare_data(
                self.models_df, indexname="files_prefix"
            )
        else:
            logger.warn("Warning: No model data found; 'models_df' is empty.")
            self.grouped, self.colors, self.hatches, self.markers = None, [], [], []

        # 2. Filter Agent Data (Houseowners)
        if not self.agents_df.empty and "Class" in self.agents_df.columns:
            self.houseowners = self.agents_df[self.agents_df["Class"] == "Houseowner"]
            self.houseowners.index = pd.MultiIndex.from_tuples(
                self.houseowners.index, names=["Step", "AgentID"]
            )
        else:
            self.houseowners = pd.DataFrame(columns=self.agents_df.columns)
            logger.warn("Warning: No agent data found; 'houseowners' DataFrame is empty.")

    def get_output_folder(self):
        """
        Constructs and returns the path to the output folder for plots.
        """
        return self.output_folder

    def get_seeds_from_filename(self, directory, files_prefix, scenario_id, run_id):
        """
        Extracts the seeds sequence from the first matching agent file in a directory.
        """
        pattern = rf"^agent_df_{files_prefix}_{scenario_id}_{run_id}_\d+\.pkl$"
        
        for filename in os.listdir(directory):
            if re.match(pattern, filename):
                # Split and grab the part before .pkl
                elements = filename.split("_")
                return elements[-1][:-4]

        raise FileNotFoundError(f"No file found with the pattern: {pattern}")

    def process_all_outputs(self):
        """
        Runs all configured comparison plotting methods.

        This method acts as a central dispatcher. It checks the global settings
        to see which comparison plots are enabled (e.g., `compare_fulfillment`,
        `compare_emissions`) and calls the corresponding methods to generate
        and save the plots.
        """
        if settings.eval.compare_fulfillment:
            self.compare_fulfilment()
            self.compare_relative_fulfilment()
        if settings.eval.compare_emissions:
            self.compare_emissions()
        if settings.eval.compare_energy_demand:
            self.compare_energy_demand()
        if settings.eval.compare_optimality:
            self.compare_optimality()
        if settings.eval.compare_opex:
            self.compare_opex()
        if settings.eval.compare_total_expenses:
            self.compare_total_expenses()
        if settings.eval.compare_heating_systems_distribution:
            self.compare_heating_systems_distribution()
        if settings.eval.compare_hs_knowledge:
            self.compare_hs_knowledge("Heating_system_heat_pump")
        if settings.eval.compare_total_effort:
            self.compare_total_effort()
            self.compare_relative_total_effort()
        if settings.eval.compare_obstacles_counts \
            or settings.eval.compare_obstacles_percentage:
            self.compare_obstacles()
            self.compare_relative_obstacles()
        if settings.eval.compare_attributes:
            self.compare_attribute_ratings()
        if settings.eval.compare_stage_flows:
            self.compare_stage_flows()
            self.compare_stage_flows_heatmap()
            self.compare_relative_stage_flows_heatmap()

        # self.to_csv()        

    def compare_fulfilment(self):
        """
        Generates and saves plots comparing scenario fulfillment.

        This method produces three distinct plots to analyse the fulfillment of
        the target scenario goals:
        1. A line plot showing the fulfillment 
        percentage over the simulation time for each scenario.
        2. A bar chart showing the fulfillment 
        of the network heating quota at the final step.
        3. A bar chart showing the final overall 
        fulfillment percentage for each scenario, 
        complete with error bars representing the standard deviation across seeds.
        """    
        # Prepare lists for final fulfillment values, error values, labels, and network shares.
        final_values = []
        final_std_values = []
        labels = []
        network_shares = []
        
        # Define mapping of heating systems to their network labels.
        network_systems = [
            "Heating_system_heat_pump_brine",
            "Heating_system_network_local",
            "Heating_system_network_district",
            "Heating_system_GP_Joule",
        ]
        
        # Create a figure for the line plot only.
        fig_line, ax_line = plt.subplots(figsize=(settings.eval.width,
                                                  settings.eval.height),
                                                  dpi=settings.eval.resolution)
        
        texts = []
        for ((_order, scenario, run_id, files_prefix), group), color, hatch, marker in zip(
                self.grouped, self.colors, self.hatches, self.markers):
            group_reset = group.reset_index(drop=True)
            scenario_fulfillment = group_reset["Scenario fulfilment"]
            scenario_fulfillment_std = group_reset["Scenario fulfilment std"]
        
            # Plot line chart for fulfillment.
            ax_line.plot(
                scenario_fulfillment,
                label = f"{_(files_prefix)}",
                color = color,
                marker = marker,
                markevery = settings.eval.markevery,
                markersize = settings.eval.markersize,
            )
            
            texts.append(ax_line.text(scenario_fulfillment.index[-1]*1.02, scenario_fulfillment.iloc[-1],
                                      f'{scenario_fulfillment.iloc[-1]:.1f} %', ha='left', va='center'))
        
            final_values.append(scenario_fulfillment.iloc[-1])
            final_std_values.append(scenario_fulfillment_std.iloc[-1])
            short_label = f"{files_prefix}".split("-")[0].strip()
            labels.append(short_label)
        
            # Extract heating distribution for the final time step.
            heating_dict = group_reset["Heating distribution"].iloc[-1]
            total_share = sum(heating_dict.values()) if heating_dict else 0
        
            # Check network fulfillment options in order.
            for system in network_systems:
                value = heating_dict.get(system, 0)
                if value > 0:
                    break
        
            network_share = (value / total_share) * 100 if total_share > 0 else 0
            network_shares.append(network_share)
        
        # Format the line plot.
        if settings.eval.title_fulfillment:
            ax_line.set_title(_("Fulfillment of target scenario"))
        ax_line.set_ylabel(_("Fulfillment, %"))
        ax_line.set_ylim(0, 110)
        
        if settings.eval.use_adjust_text:
            adjust_text(texts, #arrowprops=dict(arrowstyle="->", color='b', lw=0.5),
                        expand_axes = True,
                        )
        
        total_weeks = len(scenario_fulfillment)
        all_years = [2025 + i for i in range((total_weeks // 52) + 1)]
        years = [year for year in all_years if (year - 2025) % 5 == 0]
        year_positions = [(year - 2025) * 52 for year in years]
        ax_line.set_xticks(year_positions)
        ax_line.set_xticklabels(years)
        ax_line.legend(loc="upper left")
        
        # Save the line plot in its own file.
        outfile = (f"{self.get_output_folder()}/Fulfilment_Time_Series.png")
        logger.info(f"Store fulfillment comparison figure at {outfile}.")
        plt.savefig(
            outfile,
            bbox_inches="tight",
        )
        plt.close(fig_line)
        
        # Create a separate figure for the network quota fulfillment bar chart.
        fig_network, ax_network = plt.subplots(figsize=(settings.eval.width*settings.eval.widthfactorbox,
                                                        settings.eval.height),
                                                        dpi=settings.eval.resolution)
        x_positions = range(len(labels))
        ax_network.bar(x_positions, network_shares, color=self.colors, hatch=self.hatches)
        ax_network.set_xticks(x_positions)
        ax_network.set_xticklabels(labels, rotation=settings.eval.labelrotation, ha="right")
        ax_network.set_ylabel(_("Share (%)"))
        ax_network.set_ylim(0, 120)
        if settings.eval.title_quota:
            ax_network.set_title(_("Network quota fulfillment"), pad=10)
        
        # Display share values above each bar.
        for i, v in enumerate(network_shares):
            ax_network.text(i, v + 2, f"{v:.1f}%", ha='center', va='bottom')
        
        # Save the network quota fulfillment chart in a separate file.
        plt.savefig(
            f"{self.get_output_folder()}/Fulfillment_Network_Quota.png",
            bbox_inches="tight",
        )
        plt.close(fig_network)
        
        # Set up the bar chart for final fulfilment with error bars.
        fig_final, ax_final = plt.subplots(figsize=(13, 6), dpi=192)
        bars = ax_final.bar(labels, final_values, yerr=final_std_values, capsize=5, 
                            color=self.colors, hatch=self.hatches)
        
        ax_final.set_title(_("Fulfillment Comparison"))
        ax_final.set_xlabel(_("Scenario and Run"))
        ax_final.set_ylabel(_("Fulfillment, %"))
        ax_final.set_ylim(0, 100)
        plt.xticks(rotation=45, ha="right")
        
        # Annotate the bars with the average values.
        for bar in bars:
            height = bar.get_height()
            ax_final.text(
                bar.get_x() + bar.get_width() / 2.0,
                1.01 * height,
                f"{height:.2f}",
                ha="center",
                va="bottom",
            )
        
        # Save the final fulfilment bar chart.
        outfile = (f"{self.get_output_folder()}/Fulfilment_Bar_chart.png")
        logger.info(f"Store fulfillment comparison figure at {outfile}.")
        plt.savefig(
            outfile,
            bbox_inches="tight",
        )
        plt.clf()  # Clear the figure after saving.
    
    def compare_relative_fulfilment(self):
        """
        Generates and saves plots comparing scenario fulfillment 
        relative to a Baseline or, if there is no Baseline,
        to the first prefix in the group.
        
        Logic:
        1. Finds a scenario with "Baseline" in the name to use as 0-point.
        2. Calculates (Scenario - Baseline) for all others.
        3. Plots the difference in percentage points (pp).
        """
        grouped_data = list(self.grouped)

        # --- STEP 1: FIND THE BASELINE ---
        baseline_series = None
        baseline_label = "Unknown"
        
        for ((_order, _scen, _run, files_prefix), group) in grouped_data:
            if "Baseline" in files_prefix:
                baseline_series = group.reset_index(drop=True)["Scenario fulfilment"]
                baseline_label = files_prefix
                break
        
        # Fallback
        if baseline_series is None and grouped_data:
            ((_order, _scen, _run, files_prefix), group) = grouped_data[0]
            baseline_series = group.reset_index(drop=True)["Scenario fulfilment"]
            baseline_label = files_prefix

        # --- STEP 2: PLOT TIME SERIES (RELATIVE) ---
        fig_line, ax_line = plt.subplots(figsize=(settings.eval.width,
                                                  settings.eval.height),
                                         dpi=settings.eval.resolution)
        
        # Add a zero line (visual guide for the baseline level)
        ax_line.axhline(0, color='black', linewidth=1, linestyle='--', alpha=0.5)

        final_diff_values = []
        labels = []
        texts = []
        
        for ((_order, scenario, run_id, files_prefix), group), color, hatch, marker in zip(
                grouped_data, self.colors, self.hatches, self.markers):
            
            # SKIP BASELINE PLOTTING
            if files_prefix == baseline_label:
                continue

            group_reset = group.reset_index(drop=True)
            current_series = group_reset["Scenario fulfilment"]
            
            # Calculate difference (Scenario - Baseline)
            min_len = min(len(current_series), len(baseline_series))
            relative_series = current_series[:min_len] - baseline_series[:min_len]

            # Plot the relative line
            ax_line.plot(
                relative_series,
                label=f"{_(files_prefix)}",
                color=color,
                marker=marker,
                markevery=settings.eval.markevery,
                markersize=settings.eval.markersize,
            )
            
            # Label at the end of the line
            last_val = relative_series.iloc[-1]
            texts.append(ax_line.text(relative_series.index[-1]*1.02, last_val,
                                      f'{last_val:+.1f} pp', ha='left', va='center'))

            # Store data for Bar Chart
            final_diff_values.append(last_val)
            short_label = f"{files_prefix}".split("-")[0].strip()
            labels.append(short_label)

        # Formatting Line Plot
        if settings.eval.title_fulfillment:
            ax_line.set_title(_("Relative Fulfillment vs Baseline"))
        
        ax_line.set_ylabel(_("Difference to Baseline (pp)"))
        
        # Add Reference Box (Hidden Baseline Info)
        ref_text = f"Reference:\n{baseline_label}"
        ax_line.text(0.02, 0.95, ref_text, transform=ax_line.transAxes, 
                     fontsize=9, verticalalignment='top', 
                     bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='gray'))

        if settings.eval.use_adjust_text:
            adjust_text(texts, expand_axes=True)

        # X-Axis Formatting
        total_weeks = len(baseline_series)
        all_years = [2025 + i for i in range((total_weeks // 52) + 1)]
        years = [year for year in all_years if (year - 2025) % 5 == 0]
        year_positions = [(year - 2025) * 52 for year in years]
        ax_line.set_xticks(year_positions)
        ax_line.set_xticklabels(years)
        ax_line.legend(loc="lower left")

        outfile = (f"{self.get_output_folder()}/Fulfilment_Relative_Time_Series.png")
        logger.info(f"Store relative fulfillment figure at {outfile}.")
        plt.savefig(outfile, bbox_inches="tight")
        plt.close(fig_line)

        # --- STEP 3: PLOT BAR CHART (RELATIVE FINAL) ---
        fig_final, ax_final = plt.subplots(figsize=(13, 6), dpi=192)
        
        # Zero line
        ax_final.axhline(0, color='black', linewidth=0.8)

        # Note: 'labels' and 'final_diff_values' already exclude the baseline 
        # because we skipped it in the loop above.
        
        bars = ax_final.bar(labels, final_diff_values, 
                            color=[c for c, l in zip(self.colors, grouped_data) if l[0][3] != baseline_label], # Match colors to filtered data
                            hatch=[h for h, l in zip(self.hatches, grouped_data) if l[0][3] != baseline_label])

        ax_final.set_title(_("Final Fulfillment Difference vs Baseline"))
        ax_final.set_xlabel(_("Scenario"))
        ax_final.set_ylabel(_("Difference (pp)"))
        plt.xticks(rotation=45, ha="right")

        # Add Reference Box
        ax_final.text(0.02, 0.95, ref_text, transform=ax_final.transAxes, 
                     fontsize=12, verticalalignment='top', 
                     bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='gray'))

        # Annotate bars
        for bar in bars:
            height = bar.get_height()
            xy_text = (0, 3) if height >= 0 else (0, -12)
            
            ax_final.annotate(f"{height:+.2f}",
                              xy=(bar.get_x() + bar.get_width() / 2.0, height),
                              xytext=xy_text,
                              textcoords="offset points",
                              ha='center', va='bottom',
                              fontsize=10)

        outfile = (f"{self.get_output_folder()}/Fulfilment_Relative_Bar_chart.png")
        logger.info(f"Store relative fulfillment bar figure at {outfile}.")
        plt.savefig(outfile, bbox_inches="tight")
        plt.clf()

    def compare_stage_flows(self):
        """
        Generates a Sankey diagram where Stage 4 splits into Satisfied/Dissatisfied.
        """
        if self.models_df.empty or "Stage flows" not in self.models_df.columns:
            logger.warning("No 'Stage flows' data available for Sankey diagram.")
            return

        # --- 1. COLOR CONSTANTS ---
        C_LINK_MAIN = "rgba(44, 160, 44, 0.6)"    # Green
        C_LINK_LOOP = "rgba(255, 127, 14, 0.6)"   # Orange
        C_LINK_DROP = "rgba(214, 39, 40, 0.6)"    # Red 
        C_FLOW_AGE = "rgba(148, 103, 189, 0.6)"       # Purple
        C_FLOW_MILIEU = "rgba(23, 190, 207, 0.6)"     # Cyan
        C_FLOW_BREAKDOWN = "rgba(140, 86, 75, 0.6)"   # Brown
                
        # Node Colors
        C_NODE_RETENTION = "lightgrey" # Light Green
        C_NODE_DROP = "#ff9896"      # Light Red
        C_NODE_SPINE = "lightgrey"
        C_NODE_SUCCESS = "#2ca02c"   # Strong Green

        for ((_order, scenario, run_id, files_prefix), group) in self.grouped:
            
            final_dict = group["Stage flows"].iloc[-1]
            if isinstance(final_dict, str):
                final_dict = ast.literal_eval(final_dict)

            # --- 2. PRE-SCAN TO SORT NODES ---
            top_nodes = set()
            bottom_nodes = set()
            
            def categorize_node(stage, raw_name):
                # STAGE 1
                if stage == "Stage_1":
                    if "Satisfied" in raw_name: 
                        return "Retention: Satisfied", "top"
                
                # STAGE 2
                if stage == "Stage_2":
                    if "Current_HS_best" in raw_name: 
                        return "Drop: Old is Best", "bottom"
                
                # STAGE 4
                if stage == "Stage_4":
                    if "Satisfied" in raw_name:
                        return "Satisfied", "top"
                    if "Dissatisfied" in raw_name:
                        return "Dissatisfied", "bottom"

                # GENERIC CLEANUP
                clean = raw_name.replace("Dissatisfied_", "").replace("Desired_infeasible_", "Inf: ").replace("_", " ")
                clean = clean.replace(" to drop", "").replace(" to stage 2", "") 
                return f"Drop: {clean}", "bottom"

            # Scan for dynamic nodes
            for stage_key in ["Stage_1", "Stage_2", "Stage_3", "Stage_4"]:
                flows = final_dict.get(stage_key, {})
                for k, v in flows.items():
                    if v <= 0.01: continue
                    
                    # Skip Main Flows that link stages directly
                    if stage_key == "Stage_1" and "Dissatisfied" in k: continue # -> S2
                    if stage_key == "Stage_2" and k == "Found_desired": continue # -> S3
                    if stage_key == "Stage_3" and k == "Installed": continue # -> S4
                    if stage_key == "Stage_3" and "to_stage_2" in k: continue # -> S2 (Loop)
                    
                    name, pos = categorize_node(stage_key, k)
                    if pos == "top": top_nodes.add(name)
                    elif pos == "bottom": bottom_nodes.add(name)

            sorted_top = sorted(list(top_nodes))
            sorted_bottom = sorted(list(bottom_nodes))

            # --- 3. CONSTRUCT NODES ---
            labels_list = []
            x_coords = []
            y_coords = []
            node_colors = []
            node_map = {}
            
            def add_node_def(name, x, y, c):
                node_map[name] = len(labels_list)
                labels_list.append(name)
                x_coords.append(x)
                y_coords.append(y)
                node_colors.append(c)

            # A. TOP NODES (Retention + Stage 4 Satisfied)
            for i, name in enumerate(sorted_top):
                if name == "Satisfied":
                    add_node_def(name, 0.92, 0.35, C_NODE_SUCCESS) 
                else:
                    add_node_def(name, 0.85, 0.01 + (i * 0.06), C_NODE_RETENTION)

            # B. SPINE NODES
            spine = [
                ("Stage 1", 0.001, 0.5),
                ("Stage 2", 0.30, 0.65),
                ("Stage 3", 0.55, 0.55),
                ("Stage 4", 0.80, 0.5)
            ]
            for name, sx, sy in spine:
                add_node_def(name, sx, sy, C_NODE_SPINE)

            # C. BOTTOM NODES
            for i, name in enumerate(sorted_bottom):
                if name == "Dissatisfied":
                    add_node_def(name, 0.92, 0.65, C_NODE_DROP)
                else:
                    add_node_def(name, 0.90, 0.99 - (i * 0.05), C_NODE_DROP)
            
            # --- 4. BUILD LINKS ---
            sources, targets, values, link_labels, link_colors = [], [], [], [], []

            def add_link(src_name, tgt_name, val, label, color):
                if src_name not in node_map or tgt_name not in node_map:
                    return 
                sources.append(node_map[src_name])
                targets.append(node_map[tgt_name])
                values.append(val)
                link_labels.append(f"{label}: {val:.1f}")
                link_colors.append(color)

            # STAGE 1
            for k, v in final_dict.get("Stage_1", {}).items():
                if v <= 0.01: continue
                
                if "Satisfied" in k:
                    name, _ = categorize_node("Stage_1", k)
                    add_link("Stage 1", name, v, k, C_LINK_DROP)
                elif "Dissatisfied_age" in k:
                    add_link("Stage 1", "Stage 2", v, k, C_FLOW_AGE)
                elif "Dissatisfied_milieu" in k:
                    add_link("Stage 1", "Stage 2", v, k, C_FLOW_MILIEU)
                elif "Dissatisfied_breakdown" in k:
                    add_link("Stage 1", "Stage 2", v, k, C_FLOW_BREAKDOWN)
                elif "Dissatisfied" in k:
                    # Fallback for any other dissatisfied flows
                    add_link("Stage 1", "Stage 2", v, k, C_LINK_MAIN)
            
            # STAGE 2
            for k, v in final_dict.get("Stage_2", {}).items():
                if v <= 0.01: continue
                if k == "Found_desired":
                    add_link("Stage 2", "Stage 3", v, k, C_LINK_MAIN)
                else:
                    name, _ = categorize_node("Stage_2", k)
                    add_link("Stage 2", name, v, k, C_LINK_DROP)

            # STAGE 3
            for k, v in final_dict.get("Stage_3", {}).items():
                if v <= 0.01: continue
                if k == "Installed":
                    add_link("Stage 3", "Stage 4", v, k, C_LINK_MAIN)
                elif "to_stage_2" in k:
                    add_link("Stage 3", "Stage 2", v, k, C_LINK_LOOP)
                else:
                    name, _ = categorize_node("Stage_3", k)
                    add_link("Stage 3", name, v, k, C_LINK_DROP)

            # STAGE 4
            for k, v in final_dict.get("Stage_4", {}).items():
                if v <= 0.01: continue
                if "Satisfied" in k:
                    name, _ = categorize_node("Stage_4", k)
                    add_link("Stage 4", name, v, k, C_LINK_MAIN)
                else:
                    name, _ = categorize_node("Stage_4", k)
                    add_link("Stage 4", name, v, k, C_LINK_DROP)

            if not sources: continue

            # --- 5. PLOT ---
            fig = go.Figure()
            fig.add_trace(go.Sankey(
                arrangement = "perpendicular", 
                node = dict(
                    pad = 30,
                    thickness = 15,
                    line = dict(color = "black", width = 0.5),
                    label = labels_list,
                    color = node_colors,
                    x = x_coords, 
                    y = y_coords
                ),
                link = dict(
                    source = sources,
                    target = targets,
                    value = values,
                    label = link_labels,
                    color = link_colors
                )
            ))
            
            legend_items = [
                ("Success", C_LINK_MAIN),
                ("Loop", C_LINK_LOOP),
                ("Drop / Dissatisfaction", C_LINK_DROP),
                ("Dissatisfied: Age", C_FLOW_AGE),
                ("Dissatisfied: Milieu", C_FLOW_MILIEU),
                ("Dissatisfied: Breakdown", C_FLOW_BREAKDOWN)
            ]
            
            for name, col in legend_items:
                fig.add_trace(go.Scatter(
                    x=[None], y=[None], 
                    mode='markers',
                    marker=dict(size=12, color=col), 
                    name=name
                ))

            title_text = f"Stage Flows - {files_prefix}"
            fig.update_layout(
                title_text=title_text, 
                font_size=14, 
                width=1920, 
                height=1080,
                
                # 1. Set Backgrounds to White
                paper_bgcolor='white',
                plot_bgcolor='white',
                
                # 2. Hide Axes (Ticks, Grid, Lines)
                xaxis={
                    'showgrid': False, 
                    'zeroline': False, 
                    'visible': False
                },
                yaxis={
                    'showgrid': False, 
                    'zeroline': False, 
                    'visible': False
                },
                
                # 3. Legend Configuration
                legend=dict(
                    orientation="h", 
                    y=-0.05, 
                    x=0.5, 
                    xanchor="center",
                    bgcolor='white',
                    bordercolor='Black',
                    borderwidth=0
                ),
            )
            
            safe_suffix = re.sub(r'[^\w\-_]', '_', files_prefix)
            out_path = f"{self.get_output_folder()}/Sankey_Stage_Flows_{safe_suffix}"
            fig.write_html(f"{out_path}.html")
            try:
                fig.write_image(f"{out_path}.png")
            except Exception:
                pass
    
    def compare_stage_flows_heatmap(self):
        """
        Generates a heatmap comparing the final stage flow counts across scenarios.
        
        This method flattens the nested 'Stage flows' dictionary (Stage -> Outcome -> Count)
        into a matrix where:
        - Rows represent the specific outcome (e.g., 'Stage 1: Satisfied')
        - Columns represent the Scenario/Run
        - Cells contain the absolute count of agents
        """
        # Lazy import seaborn to ensure it doesn't break if missing, 
        # though it is standard for this type of visualization.
        if self.models_df.empty or "Stage flows" not in self.models_df.columns:
            logger.warning("No 'Stage flows' data available for heatmap.")
            return

        data_rows = []

        # 1. Extract and Flatten Data
        for ((_order, scenario, run_id, files_prefix), group) in self.grouped:
            # Get final dictionary from the last step
            final_dict = group["Stage flows"].iloc[-1]
            
            # Handle stringified dictionaries if loaded from CSV/Pickle
            if isinstance(final_dict, str):
                final_dict = ast.literal_eval(final_dict)
            
            # Flatten the dictionary: key = "Stage - Outcome", value = Count
            flat_run_data = {}
            if isinstance(final_dict, dict):
                for stage, outcomes in final_dict.items():
                    if isinstance(outcomes, dict):
                        for outcome, count in outcomes.items():
                            # Create a combined label, e.g., "Stage_1: Satisfied"
                            # We keep the stage prefix to ensure logical sorting later
                            label = f"{stage}: {outcome}" 
                            flat_run_data[label] = count
            
            # Add the Run label to the dict for indexing
            flat_run_data['Run'] = f"{_(files_prefix)}"
            data_rows.append(flat_run_data)

        if not data_rows:
            logger.warning("No valid stage flow data found to plot.")
            return

        # 2. Create DataFrame
        df_heatmap = pd.DataFrame(data_rows)
        df_heatmap.set_index('Run', inplace=True)
        
        # Transpose: Runs become columns, Outcomes become rows (better for readability)
        df_heatmap = df_heatmap.transpose()
        
        # Sort index to keep Stages grouped together (Stage_1, Stage_2...)
        df_heatmap.sort_index(inplace=True)
        
        # Fill NaNs with 0 (for outcomes that exist in some runs but not others)
        df_heatmap.fillna(0, inplace=True)

        # 3. Plotting
        # Calculate dynamic dimensions based on data size
        num_rows = len(df_heatmap)
        num_cols = len(df_heatmap.columns)
        
        # Height: Ensure at least 8 inches, add 0.5 inch per row
        fig_height = max(8, num_rows * 0.4)
        # Width: Ensure at least 10 inches, add space per column
        fig_width = max(10, num_cols * 2)

        fig, ax = plt.subplots(figsize=(fig_width, fig_height), dpi=settings.eval.dpi)
        
        # Draw Heatmap
        # fmt='g' uses general format (avoids scientific notation), or '.0f' for integers
        sns.heatmap(df_heatmap, annot=True, fmt='.0f', cmap='YlGnBu', ax=ax, 
                    linewidths=.5, cbar_kws={'label': _('Agent Count')})

        ax.set_title(_("Comparison of Stage Flows (Final Step)"))
        ax.set_xlabel(_("Scenario / Run"))
        ax.set_ylabel(_("Stage Outcome"))
        
        # Rotate labels for better readability
        plt.xticks(rotation=45, ha="right")
        plt.yticks(rotation=0)

        # 4. Save
        outfile = f"{self.get_output_folder()}/Stage_Flows_Heatmap.png"
        logger.info(f"Store stage flows heatmap at {outfile}.")
        plt.tight_layout()
        plt.savefig(outfile, bbox_inches="tight")
        plt.close(fig)
    
    def compare_relative_stage_flows_heatmap(self):
        """
        Generates a heatmap showing the relative difference in stage flows compared to a Baseline.

        Logic:
        1. Aggregates the final 'Stage flows' counts for all runs.
        2. Identifies a 'Baseline' run (or uses the first run if no Baseline exists).
        3. Calculates (Scenario Count - Baseline Count) for every outcome.
        4. Plots these differences using a diverging colormap centered at 0.
        """
        try:
            import seaborn as sns
        except ImportError:
            logger.error("Seaborn is required for heatmap plotting.")
            return

        if self.models_df.empty or "Stage flows" not in self.models_df.columns:
            logger.warning("No 'Stage flows' data available for relative heatmap.")
            return

        # --- 1. GATHER AND FLATTEN DATA ---
        data_rows = []
        
        for ((_order, scenario, run_id, files_prefix), group) in self.grouped:
            final_dict = group["Stage flows"].iloc[-1]
            if isinstance(final_dict, str):
                final_dict = ast.literal_eval(final_dict)
            
            # Flatten: "Stage_1: Satisfied" -> 705
            flat_run_data = {}
            if isinstance(final_dict, dict):
                for stage, outcomes in final_dict.items():
                    if isinstance(outcomes, dict):
                        for outcome, count in outcomes.items():
                            label = f"{stage}: {outcome}"
                            flat_run_data[label] = count
            
            flat_run_data['Run'] = f"{_(files_prefix)}"
            data_rows.append(flat_run_data)

        if not data_rows:
            return

        # Create DataFrame (Index=Run, Cols=Outcomes)
        df = pd.DataFrame(data_rows).set_index('Run')
        
        # Transpose so Outcomes are Rows
        df = df.transpose().sort_index().fillna(0)

        # --- 2. IDENTIFY BASELINE ---
        baseline_col = None
        for col in df.columns:
            if "Baseline" in col:
                baseline_col = col
                break
        
        # Fallback: Use first column if no "Baseline" found
        if baseline_col is None:
            baseline_col = df.columns[0]
            logger.info(f"No 'Baseline' found. Using '{baseline_col}' as reference.")

        # --- 3. CALCULATE DIFFERENCES ---
        # Subtract baseline values from all columns
        df_diff = df.subtract(df[baseline_col], axis=0)

        # Drop the baseline column itself (it would be a column of all zeros)
        # unless you specifically want to see it as a reference anchor.
        # Usually it's cleaner to remove it.
        if baseline_col in df_diff.columns:
            df_diff = df_diff.drop(columns=[baseline_col])
            
        if df_diff.empty:
            logger.warning("Relative dataframe is empty (only baseline provided?). Skipping plot.")
            return

        # --- 4. PLOTTING ---
        # Dynamic Sizing
        num_rows = len(df_diff)
        num_cols = len(df_diff.columns)
        fig_height = max(8, num_rows * 0.4)
        fig_width = max(10, num_cols * 2)

        fig, ax = plt.subplots(figsize=(fig_width, fig_height), dpi=settings.eval.dpi)

        # Diverging Colormap:
        # RdBu (Red-White-Blue) or vlag (Blue-White-Red).
        # center=0 ensures White is exactly at 0 difference.
        sns.heatmap(df_diff, annot=True, fmt='+.0f', center=0, cmap='RdBu', 
                    ax=ax, linewidths=.5, cbar_kws={'label': _('Difference vs Baseline')})

        ax.set_title(_("Relative Stage Flows (Scenario - Baseline)"))
        ax.set_xlabel(_("Scenario / Run"))
        ax.set_ylabel(_("Stage Outcome"))
        
        # Add a text box indicating what the baseline was
        ref_text = f"Reference:\n{baseline_col}"
        fig.text(0.02, 0.98, ref_text, fontsize=10,
                horizontalalignment='left',
                verticalalignment='top', 
                multialignment='left',
                bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))

        plt.xticks(rotation=45, ha="right")
        plt.yticks(rotation=0)

        outfile = f"{self.get_output_folder()}/Stage_Flows_Relative_Heatmap.png"
        logger.info(f"Store relative stage flows heatmap at {outfile}.")
        plt.tight_layout()
        plt.savefig(outfile, bbox_inches="tight")
        plt.close(fig)
    
    def compare_obstacles(self, step = settings.eval.compare_obstacles_step):
        """
        Compares agent decision-making obstacles at a specific point in time.

        For each target heating system, this method generates two bar charts
        visualising the number of agents who have passed each stage (obstacle)
        in the decision-making funnel:
        1.  **Absolute Counts:** A bar chart showing the total number of agents
            that have successfully passed each obstacle.
        2.  **Percentage Shares:** A bar chart showing the percentage of agents
            that passed an obstacle relative to the number who passed the
            previous one, illustrating drop-off rates at each stage.

        Parameters
        ----------
        step : int, optional
            The simulation step (row index) from which to extract the obstacle data.
            Defaults to the value in `settings.eval.compare_obstacles_step`, which
            is typically the final step (-1).
        """
        if self.models_df.empty:
            logger.warn("No model data available to plot obstacles.")
            return
    
        # Dictionary to hold the final averaged obstacle data per scenario, run, and file prefix.
        ob_final_dict = {}
    
        # Loop over each unique combination using the grouped data.
        for ((_order, scenario, run_id, files_prefix), group), color, hatch in zip(self.grouped, self.colors, self.hatches):
            group_reset = group.reset_index(drop=True)
    
            # Check if the desired step is valid for the current group.
            num_rows = len(group_reset)
            if not (-num_rows <= step < num_rows):
                logger.warn(
                    f"Step {step} is out of bounds for scenario {scenario}, run_id {run_id}, "
                    f"files_prefix {files_prefix}. This group has {num_rows} rows."
                )
                continue

            years = math.ceil(step / 52 if step != -1 else num_rows / 52)
            # Extract the "Obstacles" dictionary for the specified step.
            ob_dict = group_reset["Obstacles"].iloc[step]
    
            if not isinstance(ob_dict, dict):
                logger.warn(f"Obstacles for scenario {scenario}, run_id {run_id}, files_prefix {files_prefix} is not a dictionary.")
                continue
    
            # Create a label following the naming convention.
            label = f"{_(files_prefix)}"
    
            # Store in final dictionary, indexed by scenario/run
            ob_final_dict[label] = ob_dict
    
        # Mapping for renaming obstacle categories.
        key_mapping = {
            "Triggered": _("Triggered"),
            "Deciding": _("Deciding"),
            "Knowledge": _("Knowing"),
            "Affordability": _("Can afford"),
            "Riskiness": _("Accepted"),
            "Evaluation": _("Like"),
            "Feasibility": _("Installed")
        }
    
        # Process each heating option individually.
        heating_options = set()
        for obs_dict in ob_final_dict.values():
            heating_options.update(obs_dict.keys())  # Extract unique heating systems
    
        for hs_option in heating_options:
            # Collect data only for the specific heating option across all scenarios/runs
            hs_data = {label: ob_dict[hs_option] for label, ob_dict in ob_final_dict.items() if hs_option in ob_dict}
    
            labelsdf = getLabels(labels_sheet="files_prefix", ascending=True)
            colors = labelsdf[labelsdf["label"].isin(hs_data.keys())]["colour"].tolist()
            hatches = [None if hatch=="None" else hatch for hatch in 
                       labelsdf[labelsdf["label"].isin(hs_data.keys())]["hatch"].tolist()]
    
            # Convert the collected dictionaries to a DataFrame and TRANSPOSE IT
            df_plot = pd.DataFrame.from_dict(hs_data, orient="index").fillna(0).transpose()
    
            # Rename obstacle keys as per mapping
            df_plot = df_plot.rename(index=key_mapping)
    
            # -------------------------------
            # Plot 1: Absolute Values
            # -------------------------------
            if settings.eval.compare_obstacles_counts:
                fig, ax = plt.subplots(figsize=(settings.eval.width,
                                                 settings.eval.height), dpi=settings.eval.dpi)
                df_plot.plot(kind="bar", ax=ax, color=colors, width=0.9,
                             edgecolor="w", linewidth=2)
    
                if settings.eval.title_obstacles:
                    ax.set_title(_("Passed Obstacles Comparison for ") + 
                                 _(hs_option) + _(" in {years} years").format(years=years))
                if settings.eval.xlabel_obstacles:
                    ax.set_xlabel(_("Obstacles"))  # Obstacles on the X-axis
                ax.set_ylabel(_("Passed Agents' Count"))
                ax.set_ylim(0, 550)
                plt.xticks(rotation=45, ha="right")
    
    
                # Annotate each bar with its value.
                texts = []
                hatches_all = np.repeat(hatches, len(df_plot.index))
                for patch, hatch in zip(ax.patches, hatches_all):
                    height = patch.get_height()
                    if height == 0:
                        continue
                    patch.set_hatch(hatch)
                    texts.append(ax.text(
                        patch.get_x() + patch.get_width() / 2,
                        height + (ax.get_ylim()[1] * 0.01),
                        f"{int(height)}",
                        ha="center",
                        va="bottom",
                        bbox = dict(
                            facecolor='white',
                            alpha=0.5,
                            linewidth=0,
                            boxstyle='square,pad=0.0',
                        ),
                        fontsize=settings.eval.textannot_fontsize,
                    ))
                
                if settings.eval.use_adjust_text:
                    adjust_text(texts,
                                expand_axes = True,
                    )
                
                handles, labels = ax.get_legend_handles_labels()
                ax.legend(handles = handles, labels = labels, title=_("Scenario and Run"),
                          bbox_to_anchor=(1.05, 1), loc="upper left")
            
                # Save the absolute values plot.
                outfile = f"{self.get_output_folder()}/Obstacles_{hs_option}_{years}_years.png"
                logger.info(f"Store obstacle comparison (absolute values) figure at {outfile}.")
                    
                plt.savefig(
                    outfile,
                    bbox_inches="tight",
                )
                plt.clf()
                plt.close(fig)
    
            # -------------------------------
            # Plot 2: Percentage Shares
            # -------------------------------
            if settings.eval.compare_obstacles_percentage:
                # Define obstacle order
                obstacle_order = [_("Triggered"),_("Deciding"), _("Knowing"), _("Can afford"), _("Accepted"), _("Like"), _("Installed")]
                obstacles_to_use = [obs for obs in obstacle_order if obs in df_plot.index]
                df_ordered = df_plot.loc[obstacles_to_use]
    
                # Compute percentages:
                percent_df = df_ordered.copy()
                percent_df = percent_df.astype(float)
                percent_df.iloc[0] = (df_ordered.iloc[0] / 514) * 100
                for i in range(1, len(df_ordered)):
                    percent_df.iloc[i] = ((df_ordered.iloc[i] / df_ordered.iloc[i - 1]) * 100).astype(float)
    
                # Replace any division errors with 0.
                percent_df = percent_df.replace([np.inf, -np.inf], np.nan).fillna(0)
                
                fig, ax = plt.subplots(figsize=(settings.eval.width,
                                                 settings.eval.height), dpi=settings.eval.dpi)
                percent_df.plot(kind="bar", ax=ax, color=colors, width=0.9,
                                edgecolor="w", linewidth=1)

                ax.set_title(_("Passed Obstacles Percentages Comparison for ") + _(hs_option) + 
                             _(" in {years} years").format(years=years))
                if settings.eval.xlabel_obstacles_percentage:
                    ax.set_xlabel(_("Obstacles"))  # Obstacles on the X-axis
                ax.set_ylabel(_("Share of agents at previous level (%)"))
                ax.set_ylim(0, 110)
                plt.xticks(rotation=45, ha="right")
    
                # Annotate each bar with its percentage value.
                texts = []
                hatches_all = np.repeat(hatches, len(df_plot.index))
                for patch, hatch in zip(ax.patches, hatches_all):
                    height = patch.get_height()
                    if height == 0:
                        continue
                    patch.set_hatch(hatch)
                    texts.append(ax.text(
                        patch.get_x() + patch.get_width() / 2,
                        height + (ax.get_ylim()[1] * 0.01),
                        f"{int(height)}",
                        ha="center",
                        va="bottom",
                        bbox = dict(
                            facecolor='white',
                            alpha=0.5,
                            linewidth=0,
                            boxstyle='square,pad=0.0',
                        ),
                        fontsize=settings.eval.textannot_fontsize,
                    ))
                    
                if settings.eval.use_adjust_text:
                    adjust_text(texts, #arrowprops=dict(arrowstyle="->", color='b', lw=0.5),
                                expand_axes = True,
                    )
                handles, labels = ax.get_legend_handles_labels()
                ax.legend(handles = handles, labels = labels, title=_("Scenario and Run"), bbox_to_anchor=(1.05, 1), loc="upper left")
                # Save the percentage plot.
                outfile = f"{self.get_output_folder()}/Obstacles_Percentages_{hs_option}_{years}_years.png"
                logger.info(f"Store obstacle comparison (percentage values) figure at {outfile}.")
                plt.savefig(outfile, bbox_inches="tight",
                )
                plt.clf()
                plt.close(fig)

    def compare_relative_obstacles(self, step=settings.eval.compare_obstacles_step):
        """
        Compares agent decision-making obstacles relative to a Baseline
        or, if there is no Baseline, with the first prefix.

        Visualises the difference between scenarios and the baseline.
        1.  **Count Difference:** (Scenario Count - Baseline Count)
        2.  **Conversion Rate Difference:** (Scenario % - Baseline %) in pp.

        Parameters
        ----------
        step : int, optional
            The simulation step to analyze.
        """
        if self.models_df.empty:
            logger.warn("No model data available to plot obstacles.")
            return
    
        # --- STEP 1: GATHER DATA ---
        ob_final_dict = {}
        for ((_order, scenario, run_id, files_prefix), group), color, hatch in zip(self.grouped, self.colors, self.hatches):
            group_reset = group.reset_index(drop=True)
            num_rows = len(group_reset)
            if not (-num_rows <= step < num_rows): continue

            years = math.ceil(step / 52 if step != -1 else num_rows / 52)
            ob_dict = group_reset["Obstacles"].iloc[step]
            if not isinstance(ob_dict, dict): continue
    
            label = f"{_(files_prefix)}"
            ob_final_dict[label] = ob_dict
    
        # --- STEP 2: IDENTIFY BASELINE ---
        baseline_label = None
        for label in ob_final_dict.keys():
            if "Baseline" in label:
                baseline_label = label
                break
        
        if baseline_label is None and ob_final_dict:
            baseline_label = list(ob_final_dict.keys())[0]

        # --- STEP 3: PREPARE PLOTTING DATA ---
        key_mapping = {
            "Triggered": _("Triggered"), "Deciding": _("Deciding"), "Knowledge": _("Knowing"),
            "Affordability": _("Can afford"), "Riskiness": _("Accepted"), "Evaluation": _("Like"),
            "Feasibility": _("Installed")
        }
    
        heating_options = set()
        for obs_dict in ob_final_dict.values():
            heating_options.update(obs_dict.keys())
    
        for hs_option in heating_options:
            hs_data = {label: ob_dict[hs_option] for label, ob_dict in ob_final_dict.items() if hs_option in ob_dict}
            if not hs_data: continue

            # Create DataFrame
            df_plot = pd.DataFrame.from_dict(hs_data, orient="index").fillna(0).transpose()
            df_plot = df_plot.rename(index=key_mapping)
            
            if baseline_label not in df_plot.columns: continue

            # --- PLOT 1: RELATIVE COUNTS ---
            if settings.eval.compare_obstacles_counts:
                baseline_vals = df_plot[baseline_label]
                df_diff = df_plot.subtract(baseline_vals, axis=0)
                
                # REMOVE BASELINE FROM PLOT
                if baseline_label in df_diff.columns:
                    df_diff = df_diff.drop(columns=[baseline_label])
                
                # Get updated colors/hatches excluding baseline
                # (We re-fetch colors based on the columns remaining in df_diff)
                labelsdf = getLabels(labels_sheet="files_prefix", ascending=True)
                remaining_labels = df_diff.columns.tolist()
                
                current_colors = []
                current_hatches = []
                for lbl in remaining_labels:
                    # Find matching color/hatch for this specific label
                    row = labelsdf[labelsdf["label"] == lbl]
                    if not row.empty:
                        current_colors.append(row["colour"].values[0])
                        h_val = row["hatch"].values[0]
                        current_hatches.append(None if h_val == "None" else h_val)
                    else:
                        current_colors.append("grey") # Fallback
                        current_hatches.append(None)

                fig, ax = plt.subplots(figsize=(settings.eval.width, settings.eval.height), dpi=settings.eval.dpi)
                ax.axhline(0, color='black', linewidth=0.8)

                df_diff.plot(kind="bar", ax=ax, color=current_colors, width=0.8, edgecolor="w", linewidth=1)
    
                if settings.eval.title_obstacles:
                    ax.set_title(_("Obstacle Count Difference vs Baseline for ") + _(hs_option))
                if settings.eval.xlabel_obstacles:
                    ax.set_xlabel(_("Obstacles"))
                ax.set_ylabel(_("Difference in Agent Count"))

                # EXTEND Y-AXIS LIMITS
                # Calculate max absolute value to determine headroom
                if not df_diff.empty:
                    max_val = df_diff.max().max()
                    min_val = df_diff.min().min()
                    # Add 20% padding above and below
                    y_range = max(abs(max_val), abs(min_val))
                    if y_range == 0: y_range = 10 # Default if all are 0
                    ax.set_ylim(-y_range * 1.2, y_range * 1.2)
                
                plt.xticks(rotation=45, ha="right")

                # Reference Box
                ref_text = f"Reference:\n{baseline_label}"
                ax.text(0.02, 0.95, ref_text, transform=ax.transAxes, fontsize=12, 
                        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))

                # Annotations
                hatches_all = np.repeat(current_hatches, len(df_diff.index))
                for patch, hatch in zip(ax.patches, hatches_all):
                    height = patch.get_height()
                    patch.set_hatch(hatch)
                    if height == 0: continue
                    
                    xy_text = (0, 5) if height >= 0 else (0, -12)
                    ax.annotate(f"{int(height):+}", 
                                xy=(patch.get_x() + patch.get_width() / 2, height),
                                xytext=xy_text, textcoords="offset points",
                                ha='center', va='bottom', fontsize=10)
    
                handles, labels = ax.get_legend_handles_labels()
                ax.legend(handles=handles, labels=labels, title=_("Scenario"), bbox_to_anchor=(1.05, 1), loc="upper left")
    
                outfile = f"{self.get_output_folder()}/Obstacles_Relative_Counts_{hs_option}_{years}_years.png"
                logger.info(f"Store relative obstacle counts figure at {outfile}.")
                plt.savefig(outfile, bbox_inches="tight")
                plt.close(fig)
    
            # --- PLOT 2: RELATIVE PERCENTAGES ---
            if settings.eval.compare_obstacles_percentage:
                percent_df = df_plot.copy().astype(float)
                # Avoid division by zero for the first row if needed, but assuming constant agents here
                percent_df.iloc[0] = (df_plot.iloc[0] / 514) * 100 
                for i in range(1, len(df_plot)):
                    prev = df_plot.iloc[i - 1]
                    # Mask 0 values to avoid inf
                    prev[prev == 0] = np.nan 
                    percent_df.iloc[i] = ((df_plot.iloc[i] / prev) * 100)
                
                percent_df = percent_df.replace([np.inf, -np.inf], np.nan).fillna(0)

                baseline_pcts = percent_df[baseline_label]
                percent_diff_df = percent_df.subtract(baseline_pcts, axis=0)

                obstacle_order = [_("Triggered"),_("Deciding"), _("Knowing"), _("Can afford"), _("Accepted"), _("Like"), _("Installed")]
                obstacles_to_use = [obs for obs in obstacle_order if obs in percent_diff_df.index]
                percent_diff_df = percent_diff_df.loc[obstacles_to_use]

                # REMOVE BASELINE
                if baseline_label in percent_diff_df.columns:
                    percent_diff_df = percent_diff_df.drop(columns=[baseline_label])

                # Re-fetch colors for percentages (same logic as above)
                remaining_labels = percent_diff_df.columns.tolist()
                current_colors = []
                current_hatches = []
                for lbl in remaining_labels:
                    row = labelsdf[labelsdf["label"] == lbl]
                    if not row.empty:
                        current_colors.append(row["colour"].values[0])
                        h_val = row["hatch"].values[0]
                        current_hatches.append(None if h_val == "None" else h_val)
                    else:
                        current_colors.append("grey")
                        current_hatches.append(None)

                fig, ax = plt.subplots(figsize=(settings.eval.width, settings.eval.height), dpi=settings.eval.dpi)
                ax.axhline(0, color='black', linewidth=0.8)

                percent_diff_df.plot(kind="bar", ax=ax, color=current_colors, width=0.8, edgecolor="w", linewidth=1)

                ax.set_title(_("Conversion Rate Difference vs Baseline for ") + _(hs_option))
                if settings.eval.xlabel_obstacles_percentage:
                    ax.set_xlabel(_("Obstacles"))
                ax.set_ylabel(_("Difference in Conversion Rate (pp)"))

                # EXTEND Y-AXIS LIMITS
                if not percent_diff_df.empty:
                    max_val = percent_diff_df.max().max()
                    min_val = percent_diff_df.min().min()
                    y_range = max(abs(max_val), abs(min_val))
                    if y_range == 0: y_range = 10
                    # Slightly larger buffer for percentages as text is often longer
                    ax.set_ylim(-y_range * 1.3, y_range * 1.3)

                plt.xticks(rotation=45, ha="right")
                
                ax.text(0.02, 0.95, ref_text, transform=ax.transAxes, fontsize=12, 
                        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))

                hatches_all = np.repeat(current_hatches, len(percent_diff_df.index))
                for patch, hatch in zip(ax.patches, hatches_all):
                    height = patch.get_height()
                    patch.set_hatch(hatch)
                    xy_text = (0, 5) if height >= 0 else (0, -12)
                    ax.annotate(f"{height:+.1f} pp",
                                xy=(patch.get_x() + patch.get_width() / 2, height),
                                xytext=xy_text, textcoords="offset points",
                                ha='center', va='bottom', fontsize=10)
    
                handles, labels = ax.get_legend_handles_labels()
                ax.legend(handles=handles, labels=labels, title=_("Scenario"), bbox_to_anchor=(1.05, 1), loc="upper left")

                outfile = f"{self.get_output_folder()}/Obstacles_Relative_Percentages_{hs_option}_{years}_years.png"
                logger.info(f"Store relative obstacle percentages figure at {outfile}.")
                plt.savefig(outfile, bbox_inches="tight")
                plt.close(fig)
        
    def compare_hs_knowledge(self, heating_system_type):
        """
        Plots the evolution of agents' knowledge about a specific heating system.

        This method generates a line plot showing the cumulative number of agents
        who have gained knowledge about the specified `heating_system_type` over
        the course of the simulation.

        Parameters
        ----------
        heating_system_type : str
            The class name of the heating system to analyze 
            (e.g., "Heating_system_heat_pump").
        """
    
        # Setting up the line plot
        fig, ax = plt.subplots(figsize=(13, 6), dpi=192)
    
        # Initialize a list to store final values for the bar chart and boxplot
        final_values = []
        labels = []
        new_columns = {}
    
        for ((_order, scenario, run_id, files_prefix), group), color in zip(
            self.grouped, self.colors
        ):
            # Extract the counts for the selected heating system type
            column_name = f"{heating_system_type} {files_prefix}"
            group_heating_counts = group["Known heating systems"].apply(
                lambda x: x.get(heating_system_type, 0) if isinstance(x, dict) else 0
            )
            new_columns[column_name] = group_heating_counts.diff()
    
            # Convert week numbers to years (assuming week 0 = start of 2025)
            weeks = np.arange(len(group_heating_counts))
            years = 2025 + (weeks / 52)  # Convert weeks to decimal years
    
            # Plot the heating system counts over time
            ax.plot(
                years,
                group_heating_counts.values,
                label=f"{files_prefix}",
                color=color,
            )
    
            # Append the last value of the series to the final_values list
            final_values.append(group_heating_counts.iloc[-1])
            labels.append(f"{files_prefix}")
    
        # Combine the new columns DataFrame with the original rate_of_change DataFrame
        new_columns_df = pd.DataFrame(new_columns)
        self.rate_of_change = pd.concat([self.rate_of_change, new_columns_df], axis=1)
    
        # Customizing the x-axis to show only selected years (e.g., 2030, 2035, etc.)
        ax.set_xticks(np.arange(2025, max(years) + 1, 5))  # Show ticks every 5 years
        ax.set_xticklabels([str(int(y)) for y in np.arange(2025, max(years) + 1, 5)])  # Set labels as integer years
    
        # Customizing the line plot
        ax.set_title(_("Agents' knowledge about heating technologies"))
        ax.set_ylabel(_("Agents"))
        ax.legend()
    
        # Save the line plot
        outfile = f"{self.get_output_folder()}/Known_heating_technologies.png"
        logger.info(f"Store HS knowledge comparison figure at {outfile}.")
        
        plt.savefig(outfile, bbox_inches="tight")
        plt.clf()  # Clear the figure

    def compare_emissions(self):
        """
        Generates plots comparing CO2 emissions across scenarios.

        This comprehensive method creates four different visualisations to
        analyse the average CO2 emissions per building:
        1.  **Time Series:** A line plot showing the trend of average emissions
            over the simulation period.
        2.  **Final Value Bar Chart:** A bar chart comparing the average emissions
            at the final simulation step.
        3.  **Boxplot:** A boxplot showing the distribution of final emission
            values across all agents for each scenario.
        4.  **Yearly Average Bar Chart:** A grouped bar chart showing the
            year-over-year average emissions, allowing for comparison of
            annual trends between scenarios.
        """
        if not self.grouped:
            logger.info("Grouped model data is empty")
        else:
            filtered = self.houseowners[["scenario", "run_id", "files_prefix", "Emissions"]]
            grouped = filtered.groupby(["scenario", "run_id", "files_prefix"])
        
            # Setting up the line plot
            fig, ax = plt.subplots(figsize=(settings.eval.width,
                                            settings.eval.height), dpi=192)
            non_aggregated_data = {}
            final_values = []
            labels = []
            new_columns = {}
        
            for ((scenario, run_id, files_prefix), group), color in zip(
                grouped, self.colors
            ):
                non_aggregated_data[f"{files_prefix}"] = (
                    group.reset_index(level=1)["Emissions"].div(1000000).dropna().to_list()
                )
        
            texts = []
            for ((_order, _scenario, run_id, files_prefix), group), color, hatch, marker in zip(
                self.grouped, self.colors, self.hatches, self.markers
            ):
                column_name = f"Emissions {files_prefix}"
                new_columns[column_name] = group["Emissions"].fillna(0).diff()
        
                group = group.reset_index(drop=True)
                weeks = np.arange(len(group))  # Get week indices
                years = 2025 + (weeks / 52)  # Convert weeks to years
        
                # Convert emissions to tons for readability
                emissions = group["Emissions"] / 1000000
                ax.plot(
                    years,
                    emissions,
                    label=f"{files_prefix}",
                    color=color,
                    marker=marker,
                    markevery=settings.eval.markevery,
                    markersize=settings.eval.markersize,
                )
                
                texts.append(ax.text(years[0]+(years[-1]-years[0])*1.02, emissions.iloc[-1],
                        f'{emissions.iloc[-1]:.1f} t', ha='left', va='center'))
                    
                # Append the last emissions value of the series to the final_values list
                final_values.append(emissions.iloc[-1])
                labels.append(f"{files_prefix}")
        
            # Combine the new columns DataFrame with the original rate_of_change DataFrame
            new_columns_df = pd.DataFrame(new_columns)
            self.rate_of_change = pd.concat([self.rate_of_change, new_columns_df], axis=1)
        
            # Customizing the x-axis to show only selected years (e.g., 2030, 2035, etc.)
            ax.set_xticks(np.arange(2025, max(years) + 1, 5))  # Show ticks every 5 years
            ax.set_xticklabels([str(int(y)) for y in np.arange(2025, max(years) + 1, 5)])  # Set labels as integer years
        
            # Customizing the line plot
            if settings.eval.title_emissions:
                ax.set_title(_("Total Emissions Comparison"))
            ax.set_ylabel(_("Tons of CO2 equivalent per building"))
            ax.set_ylim(0, None)
            ax.legend()
        
            if settings.eval.use_adjust_text:
                adjust_text(texts, expand_axes = True)
            
            # Save the line plot
            outfile = f"{self.get_output_folder()}/Emissions_Time_Series.png"
            logger.info(f"Store emissions comparison figure at {outfile}.")
            plt.tight_layout()
            plt.savefig(outfile, bbox_inches="tight",
            )
            plt.clf()  # Clear the figure
        
            # Combine labels and values into a list of tuples and sort them
            #label_value_pairs = sorted(zip(labels, final_values), key=lambda x: x[1])
            #labels, final_values = zip(*label_value_pairs)
        
            # Setting up the bar chart
            fig, ax1 = plt.subplots(figsize=(13, 6), dpi=settings.eval.dpi)
            bars = ax1.bar(labels, final_values, color=self.colors, hatch=self.hatches,
                           width = 0.9, edgecolor="w", linewidth=1)
            # Customizing the bar chart
            if settings.eval.title_emissions:
                ax1.set_title(_("Average Emissions Comparison"), pad=20)
            ax1.set_xlabel(_("Scenario and Run"))
            ax1.set_ylabel(_("Tons of CO2 equivalent per building"))
            plt.setp(ax1.get_xticklabels(), rotation=30)
            ax1.set(ylim=(0, max(final_values)*1.3))
            
            # Annotating the bar chart with the values above the bars
            for bar in bars:
                height = bar.get_height()
                ax1.text(
                    bar.get_x() + bar.get_width() / 2.0,
                    1.01 * height,
                    f"{height:.1f}",
                    ha="center",
                    va="bottom",
                )
            
    
            # Save the bar chart separately
            outfile = f"{self.get_output_folder()}/Emissions_Bar_Chart.png"
            logger.info(f"Store final emissions bar comparison figure at {outfile}.")

            plt.tight_layout()
            plt.savefig(
                outfile, bbox_inches="tight",
            )
            plt.clf()  # Clear the figure after saving
        
            # Setting up the boxplot
            if non_aggregated_data:
                fig, ax2 = plt.subplots(figsize=(settings.eval.width, settings.eval.height), dpi=settings.eval.resolution)
                ax2.boxplot(non_aggregated_data.values(), labels=non_aggregated_data.keys())
                if settings.eval.title_emissions:
                    ax2.set_title(_("Average Emissions Comparison - Boxplot"))
                ax2.set_xlabel(_("Scenario and Run"))
                ax2.set_ylabel(_("Tons of CO2 equivalent"))
                plt.setp(ax2.get_xticklabels(), rotation=0) #, ha="right")
        
                # Save the boxplot separately
                outfile = f"{self.get_output_folder()}/Emissions_Boxplot.png"
                logger.info(f"Store emissions comparison figure at {outfile}.")
                plt.savefig(
                    outfile, bbox_inches="tight",
                )
                plt.clf()  # Clear the figure after saving
            
            # --- New code: Yearly Average Bar Chart ---
            # This chart aggregates the time series by averaging every 52 datapoints (one year),
            # then plots a grouped bar chart with each bar representing a year, starting at 2025.
            yearly_data = {}
            max_years = 0
        
            for ((_order, scenario, run_id, files_prefix), group) in self.grouped:
                group = group.reset_index(drop=True)
                emissions = group["Emissions"] / 1000000  # Convert to tons for readability
                n_years = len(emissions) // 52  # Number of complete years available
                if n_years == 0:
                    continue  # Skip if there isn't enough data for one full year
                # Compute average emissions for each year (each 52 datapoints)
                yearly_avg = [emissions[i*52:(i+1)*52].mean() for i in range(n_years)]
                yearly_data[files_prefix] = yearly_avg
                if n_years > max_years:
                    max_years = n_years
            
            if yearly_data:
                fig, ax3 = plt.subplots(figsize=(13, 6), dpi=settings.eval.dpi)
                x = np.arange(max_years)  # One tick per year
                num_series = len(yearly_data)
                bar_width = 0.8 / num_series  # Adjust width so bars don't overlap
            
                # Plot a grouped bar for each scenario's yearly averages
                for i, (label, averages) in enumerate(yearly_data.items()):
                    bars = ax3.bar(
                        x + i * bar_width, averages,
                        width=bar_width,
                        label=label,
                        color=self.colors[i],
                        hatch=self.hatches[i],
                        edgecolor="w",
                        linewidth=1
                    )
                    
                    # Annotate each bar
                    for bar in bars:
                        height = bar.get_height()
                        ax3.text(
                            bar.get_x() + bar.get_width() / 2.0,
                            height * 1.01,
                            f"{height:.1f}",  # Round to whole number
                            ha="center",
                            va="bottom",
                            fontsize=8
                        )
            
                # Center x-ticks for the grouped bars
                ax3.set_xticks(x + (bar_width * (num_series - 1)) / 2)
                ax3.set_xticklabels([str(2025 + i) for i in range(max_years)])
                if settings.eval.title_emissions:
                    ax3.set_title(_("Yearly Average Emissions Comparison"))
                ax3.set_ylabel(_("Tons of CO2 equivalent per building"))
                plt.setp(ax3.get_xticklabels(), rotation=45, ha="right")
                ax3.legend()
            
                # Save the yearly average bar chart using the naming approach
                outfile = f"{self.get_output_folder()}/Emissions_Yearly_Avg_Bar_Chart.png"
                logger.info(f"Store emissions comparison figure at {outfile}.")
                plt.savefig(outfile, bbox_inches="tight")
                plt.clf()
            
    def compare_energy_demand(self):
        """
        Generates plots comparing the average energy demand of houses.

        This method creates three visualisations to analyse the average energy
        demand per building across different scenarios:
        1.  **Time Series:** A line plot showing the trend of average energy
            demand over the simulation period.
        2.  **Final Value Bar Chart:** A bar chart comparing the average energy
            demand at the final simulation step.
        3.  **Boxplot:** A boxplot showing the distribution of final energy demand
            values across all agents for each scenario.
        """
        if self.houseowners.empty:
            logger.info("agent_df is empty, energy demand won't be drawn")
            return
        filtered = self.houseowners[
            ["scenario", "run_id", "files_prefix", "Energy demand"]
        ]
        grouped = filtered.groupby(["scenario", "run_id", "files_prefix"])
    
        # Setting up the line plot
        fig, ax = plt.subplots(figsize=(13, 6), dpi=192)
        non_aggregated_data = {}
        final_values = []
        labels = []
        new_columns = {}
    
        for ((scenario, run_id, files_prefix), group), color in zip(
            grouped, self.colors
        ):
            non_aggregated_data[f"{files_prefix}"] = (
                group.reset_index(level=1)["Energy demand"].div(1000).dropna().to_list()
            )
    
        for ((_order, scenario, run_id, files_prefix), group), color in zip(
            self.grouped, self.colors
        ):
            column_name = f"Energy demand {files_prefix}"
            new_columns[column_name] = group["Energy demand"].fillna(0).diff()
    
            group = group.reset_index(drop=True)
            weeks = np.arange(len(group))  # Get week indices
            years = 2025 + (weeks / 52)  # Convert weeks to years
    
            # Convert energy demand to MWh for plotting
            demand = group["Energy demand"] / 1000
            ax.plot(
                years,
                demand,
                label=f"{files_prefix}",
                color=color,
            )
    
            # Append the last energy demand value of the series to the final_values list
            final_values.append(demand.iloc[-1])
            labels.append(f"{files_prefix}")
    
        # Combine the new columns DataFrame with the original rate_of_change DataFrame
        new_columns_df = pd.DataFrame(new_columns)
        self.rate_of_change = pd.concat([self.rate_of_change, new_columns_df], axis=1)
    
        # Customizing the x-axis to show only selected years (e.g., 2030, 2035, etc.)
        ax.set_xticks(np.arange(2025, max(years) + 1, 5))  # Show ticks every 5 years
        ax.set_xticklabels([str(int(y)) for y in np.arange(2025, max(years) + 1, 5)])  # Set labels as integer years
    
        # Customizing the line plot
        ax.set_title(_("Average House Energy Demand Comparison"))
        ax.set_ylabel(_("MWh per year per building"))
        ax.set_ylim(0, None)
        ax.legend()
    
        # Save the line plot
        outfile = f"{self.get_output_folder()}/Energy_Demand_Time_Series.png"
        logger.info(f"Store energy demand comparison figure at {outfile}.")
                
        plt.savefig(outfile, bbox_inches="tight")
        plt.clf()  # Clear the figure
    
        # Combine labels and values into a list of tuples and sort them
        label_value_pairs = sorted(zip(labels, final_values), key=lambda x: x[1])
        labels, final_values = zip(*label_value_pairs)
    
        # Setting up the bar chart
        fig, ax1 = plt.subplots(figsize=(13, 6), dpi=settings.eval.dpi)
        bars = ax1.bar(labels, final_values, color=self.colors,
                       width = 0.9, edgecolor="w", linewidth=1)

        # Customizing the bar chart
        ax1.set_title(_("Average House Energy Demand Comparison"))
        ax1.set_xlabel(_("Scenario and Run"))
        ax1.set_ylabel(_("MWh per year"))
        plt.setp(ax1.get_xticklabels(), rotation=45, ha="right")

        # Annotating the bar chart with the values above the bars
        for bar in bars:
            height = bar.get_height()
            ax1.text(
                bar.get_x() + bar.get_width() / 2.0,
                1.01 * height,
                f"{height:.2f}",
                ha="center",
                va="bottom",
            )

        # Save the bar chart separately
        outfile = f"{self.get_output_folder()}/Energy_Demand_Bar_Chart.png"
        logger.info(f"Store energy demand bar chart comparison figure at {outfile}.")
        plt.savefig(outfile, bbox_inches="tight")
        plt.clf()  # Clear the figure after saving

        # Setting up the boxplot
        fig, ax2 = plt.subplots(figsize=(13, 6), dpi=192)
        ax2.boxplot(non_aggregated_data.values(), labels=non_aggregated_data.keys())
        ax2.set_title(_("Energy Demand Comparison - Boxplot"))
        ax2.set_xlabel(_("Scenario and Run"))
        ax2.set_ylabel(_("MWh per year"))
        plt.setp(ax2.get_xticklabels(), rotation=45, ha="right")

        # Save the boxplot separately
        outfile = f"{self.get_output_folder()}/Energy_Demand_Boxplot.png"
        logger.info(f"Store energy demand boxplot comparison figure at {outfile}.")
                
        plt.savefig(outfile, bbox_inches="tight")
        plt.clf()  # Clear the figure after saving

    def compare_optimality(self):
        """
        Generates plots comparing the optimality of agents' choices.

        Optimality measures how close an agent's chosen heating system is to
        the best possible option they were aware of (a ratio of 1.0 is optimal).
        This method creates three plots to visualise this metric:
        1.  **Time Series:** A line plot showing the average optimality ratio
            over the simulation period.
        2.  **Final Value Bar Chart:** A bar chart comparing the average
            optimality at the final simulation step.
        3.  **Boxplot:** A boxplot showing the distribution of final optimality
            ratios across all agents for each scenario.
        """
        if self.houseowners.empty:
            print("agent_df is empty, optimality won't be drawn")
            return
        filtered = self.houseowners[
            ["scenario", "run_id", "files_prefix", "Suboptimality"]
        ]
        grouped = filtered.groupby(["scenario", "run_id", "files_prefix"])
    
        # Setting up the line plot
        fig, ax = plt.subplots(figsize=(13, 6), dpi=192)
        non_aggregated_data = {}
        final_values = []
        labels = []
        new_columns = {}
    
        for ((scenario, run_id, files_prefix), group), color in zip(
            grouped, self.colors
        ):
            suboptimality = (
                group.reset_index(level=1).groupby("Step")["Suboptimality"].mean()
            )
    
            column_name = f"Suboptimality {files_prefix}"
            new_columns[column_name] = suboptimality.fillna(0).diff()
    
            # Convert weeks to years (assuming Step represents weeks since 2025)
            weeks = suboptimality.index.to_numpy()
            years = 2025 + (weeks / 52)  # Convert weeks to decimal years
    
            ax.plot(
                years,
                suboptimality,
                label=f"{files_prefix}",
                color=color,
            )
    
            # Append the last suboptimality value of the series to the final_values list
            non_aggregated_data[f"{files_prefix}"] = (
                group.reset_index(level=1)["Suboptimality"].dropna().to_list()
            )
    
            final_values.append(suboptimality.iloc[-1])
            labels.append(f"{files_prefix}")
    
        # Combine the new columns DataFrame with the original rate_of_change DataFrame
        new_columns_df = pd.DataFrame(new_columns)
        self.rate_of_change = pd.concat([self.rate_of_change, new_columns_df], axis=1)
    
        # Customizing the x-axis to show only selected years (e.g., 2030, 2035, etc.)
        tick_years = np.arange(2025, max(years) + 1, 5)  # Show ticks every 5 years
        ax.set_xticks(tick_years)
        ax.set_xticklabels([str(int(y)) for y in tick_years])  # Convert to whole numbers
    
        # Customizing the line plot
        ax.set_title(_("Optimality Comparison"))
        ax.set_ylabel(_("Optimality, ratio"))
        ax.set_ylim(0, None)
        ax.legend()
    
        # Save the line plot
        outfile = f"{self.get_output_folder()}/Optimality_Time_Series.png"
        logger.info(f"Store optimality line comparison figure at {outfile}.")
        plt.savefig(outfile, bbox_inches="tight")
        plt.clf()  # Clear the figure
    
        # Combine labels and values into a list of tuples and sort them
        label_value_pairs = sorted(zip(labels, final_values), key=lambda x: x[1])
        labels, final_values = zip(*label_value_pairs)
    
        # Setting up the bar chart
        fig, ax1 = plt.subplots(figsize=(13, 6), dpi=settings.eval.dpi)
        bars = ax1.bar(labels, final_values, color=self.colors,
                       width = 0.9, edgecolor="w", linewidth=1)

        # Customizing the bar chart
        ax1.set_title(_("Optimality Comparison"))
        ax1.set_xlabel(_("Scenario and Run"))
        ax1.set_ylabel(_("Optimality, ratio"))
        plt.setp(ax1.get_xticklabels(), rotation=45, ha="right")

        # Annotating the bar chart with the values above the bars
        for bar in bars:
            height = bar.get_height()
            ax1.text(
                bar.get_x() + bar.get_width() / 2.0,
                1.01 * height,
                f"{height:.2f}",
                ha="center",
                va="bottom",
            )

        # Save the bar chart separately
        outfile = f"{self.get_output_folder()}/Optimality_Bar_Chart.png"
        logger.info(f"Store optimality bar chart comparison figure at {outfile}.")
        plt.savefig(outfile, bbox_inches="tight")
        plt.clf()  # Clear the figure after saving

        # Setting up the boxplot
        fig, ax2 = plt.subplots(figsize=(13, 6), dpi=192)
        ax2.boxplot(non_aggregated_data.values(), labels=non_aggregated_data.keys())
        ax2.set_title(_("Optimality Comparison - Boxplot"))
        ax2.set_xlabel(_("Scenario and Run"))
        ax2.set_ylabel(_("Optimality, ratio"))
        plt.setp(ax2.get_xticklabels(), rotation=45, ha="right")

        # Save the boxplot separately
        outfile = f"{self.get_output_folder()}/Optimality_Boxplot.png"
        logger.info(f"Store optimality boxplot comparison figure at {outfile}.")
        plt.savefig(outfile, bbox_inches="tight")
        plt.clf()  # Clear the figure after saving

    def compare_opex(self):
        """
        Generates plots comparing the average operating expenses (OPEX).

        This method visualises the average annual operating expenses, including
        fuel and maintenance costs, for households in each scenario. It produces
        three plots:
        1.  **Time Series:** A line plot showing the trend of average OPEX over
            the simulation period.
        2.  **Final Value Bar Chart:** A bar chart comparing the average OPEX at
            the final simulation step.
        3.  **Boxplot:** A boxplot showing the distribution of final OPEX values
            across all agents for each scenario.
        """
        if self.houseowners.empty:
            print("agent_df is empty, opex won't be drawn")
            return
        filtered = self.houseowners[["scenario", "run_id", "files_prefix", "Opex"]]
        grouped = filtered.groupby(["scenario", "run_id", "files_prefix"])
    
        # Setting up the line plot
        fig, ax = plt.subplots(figsize=(13, 6), dpi=192)
        non_aggregated_data = {}
        final_values = []
        labels = []
        new_columns = {}
    
        for ((scenario, run_id, files_prefix), group), color in zip(
            grouped, self.colors
        ):
            column_name = f"Opex {files_prefix}"
            new_columns[column_name] = (
                group.reset_index(level=1)
                .groupby("Step")["Opex"]
                .mean()
                .fillna(0)
                .diff()
            )
    
            opex = group.reset_index(level=1).groupby("Step")["Opex"].mean() / 1000
    
            # Convert weeks to years (assuming Step represents weeks since 2025)
            weeks = opex.index.to_numpy()
            years = 2025 + (weeks / 52)  # Convert weeks to decimal years
    
            ax.plot(
                years,
                opex,
                label=_(files_prefix),
                color=color,
            )
    
            non_aggregated_data[f"{files_prefix}"] = (
                group.reset_index(level=1)["Opex"].div(1000).dropna().to_list()
            )
            # Append the last operating expenses value of the series to the final_values list
            final_values.append(opex.iloc[-1])
            labels.append(_(files_prefix))
    
        # Combine the new columns DataFrame with the original rate_of_change DataFrame
        new_columns_df = pd.DataFrame(new_columns)
        self.rate_of_change = pd.concat([self.rate_of_change, new_columns_df], axis=1)
    
        # Customizing the x-axis to show only selected years (e.g., 2030, 2035, etc.)
        tick_years = np.arange(2025, max(years) + 1, 5)  # Show ticks every 5 years
        ax.set_xticks(tick_years)
        ax.set_xticklabels([str(int(y)) for y in tick_years])  # Convert to whole numbers
    
        # Customizing the line plot
        ax.set_title(_("Average Operating Expenses Comparison"))
        ax.set_ylabel(_("Thousands of EUR"))
        ax.set_ylim(0, None)
        ax.legend()
    
        # Save the line plot
        outfile = f"{self.get_output_folder()}/Opex_Time_Series.png"
        logger.info(f"Store OPEX line comparison figure at {outfile}.")
        plt.savefig(outfile, bbox_inches="tight")
        plt.clf()  # Clear the figure
    
        # Combine labels and values into a list of tuples and sort them
        label_value_pairs = sorted(zip(labels, final_values), key=lambda x: x[1])
        labels, final_values = zip(*label_value_pairs)
    
        # Setting up the bar chart
        fig, ax1 = plt.subplots(figsize=(13, 6), dpi=settings.eval.dpi)
        bars = ax1.bar(labels, final_values, color=self.colors,
                       width = 0.9, edgecolor="w", linewidth=1)

        # Customizing the bar chart
        ax1.set_title(_("Average Operating Expenses Comparison"))
        ax1.set_xlabel(_("Scenario and Run"))
        ax1.set_ylabel(_("Thousands of EUR"))
        plt.setp(ax1.get_xticklabels(), rotation=45, ha="right")

        # Annotating the bar chart with the values above the bars
        for bar in bars:
            height = bar.get_height()
            ax1.text(
                bar.get_x() + bar.get_width() / 2.0,
                1.01 * height,
                f"{height:.2f}",
                ha="center",
                va="bottom",
            )

        # Save the bar chart separately
        outfile = f"{self.get_output_folder()}/Opex_Bar_Chart.png"
        logger.info(f"Store OPEX bar chart comparison figure at {outfile}.")
        plt.savefig(outfile, bbox_inches="tight")
        
        plt.clf()  # Clear the figure after saving

        # Setting up the boxplot
        fig, ax2 = plt.subplots(figsize=(13, 6), dpi=192)
        ax2.boxplot(non_aggregated_data.values(), labels=non_aggregated_data.keys())
        ax2.set_title(_("Operating Expenses Comparison - Boxplot"))
        ax2.set_xlabel(_("Scenario and Run"))
        ax2.set_ylabel(_("Thousands of EUR"))
        plt.setp(ax2.get_xticklabels(), rotation=45, ha="right")

        # Save the boxplot separately
        outfile = f"{self.get_output_folder()}/Opex_Boxplot.png"
        logger.info(f"Store OPEX bar chart comparison figure at {outfile}.")
        plt.savefig(outfile, bbox_inches="tight")
        plt.clf()  # Clear the figure after saving
    
    def compare_total_expenses(self):
        """
        Generates plots comparing the Levelized Cost of Heat (LCOH).

        This method visualises the average LCOH, representing the total cost of
        a heating system per unit of heat delivered over its lifetime. It produces
        two plots for comparison across scenarios:
        1.  **Time Series:** A line plot showing the trend of the average LCOH
            over the simulation period.
        2.  **Final Value Bar Chart:** A bar chart comparing the average LCOH at
            the final simulation step, including error bars to show the
            standard deviation across different seeds.
        """
        # Setting up the line plot
        fig, ax = plt.subplots(
            figsize=(13, 6), dpi=192
        )  # Adjusted DPI for standard screens
    
        # Initialize lists to store final values and their standard deviations for the bar chart
        final_values = []
        final_std_values = []
        labels = []
        new_columns = {}
    
        for ((_order, scenario, run_id, files_prefix), group), color in zip(
            self.grouped, self.colors
        ):
            column_name = f"Total expenses {files_prefix}"
            new_columns[column_name] = group["Total expenses"].fillna(0).diff()
    
            group_reset = group.reset_index(drop=True)
            total_expenses = group_reset["Total expenses"]
            total_expenses_std = group_reset["Total expenses std"]
    
            # Plot the line
            ax.plot(
                total_expenses,
                label=_(files_prefix) ,
                color=color,
            )
    
            # Append the final average and std values of the series for the bar chart
            final_values.append(total_expenses.iloc[-1])
            final_std_values.append(total_expenses_std.iloc[-1])
            labels.append(_(files_prefix))
    
        # Combine the new columns DataFrame with the original rate_of_change DataFrame
        new_columns_df = pd.DataFrame(new_columns)
        self.rate_of_change = pd.concat([self.rate_of_change, new_columns_df], axis=1)
    
        # Customizing the line plot
        ax.set_title(_("Annual total expenses per household"))
        ax.set_ylabel(_("Expenses, EUR"))
        ax.set_ylim(0, None)
    
        # Adjust x-axis to show only every 5th year starting from 2025
        total_weeks = len(total_expenses)
        all_years = [2025 + i for i in range((total_weeks // 52) + 1)]
        years = [year for year in all_years if (year - 2025) % 5 == 0]
        year_positions = [(year - 2025) * 52 for year in years]
        ax.set_xticks(year_positions)
        ax.set_xticklabels(years)
        ax.legend()
    
        # Save the line plot
        outfile = f"{self.get_output_folder()}/Total_Expenses_Time_Series.png"
        logger.info(f"Store total expenses line chart comparison figure at {outfile}.")
        plt.savefig(outfile, bbox_inches="tight")
        plt.clf()
    
        # Setting up the bar chart
        fig, ax = plt.subplots(figsize=(13, 6), dpi=settings.eval.dpi)
        # Draw bar chart with error bars (standard deviation)
        bars = ax.bar(labels, final_values, yerr=final_std_values, capsize=5, color=self.colors,
                      width = 0.9, edgecolor="w", linewidth=1)
    
        # Customizing the bar chart
        ax.set_title(_("Annual Total Expenses per Household comparison"))
        ax.set_xlabel(_("Scenario and Run"))
        ax.set_ylabel(_("Expenses, EUR"))
        ax.set_ylim(0, None)
        plt.xticks(rotation=45, ha="right")
    
        # Annotate the bars with the average values
        for bar in bars:
            height = bar.get_height()
            ax.text(
                bar.get_x() + bar.get_width() / 2.0,
                1.01 * height,
                f"{height:.2f}",
                ha="center",
                va="bottom",
            )
    
        # Save the bar chart
        outfile = f"{self.get_output_folder()}/Total_Expenses_Bar_Chart.png"
        logger.info(f"Store total expenses bar chart comparison figure at {outfile}.")
        plt.savefig(outfile, bbox_inches="tight")
        plt.clf()  # Clear the figure after saving
        
    def compare_total_effort(self):
        """
        Creates a radar (spider) chart to visualise total effort trade-offs.

        This method compares scenarios across several "effort" dimensions, such as
        the total volume of subsidies paid, loans taken, and the cumulative
        cognitive resource spent by agents. The resulting radar chart provides
        a holistic view of the resources required to achieve the scenario
        outcomes, making it easy to spot trade-offs.
        """
        # Define the categories (axes) for the radar chart
        categories = ["Subsidies", "Loans", "Cognitive resource", "Scenario fulfilment"]
        N = len(categories)
    
        # First pass: gather final values for each category across all groups for normalization
        all_final_values = {cat: [] for cat in categories}
        for ((_order, scenario, run_id, files_prefix), group) in self.grouped:
            for cat in categories:
                all_final_values[cat].append(group[cat].iloc[-1])
        
        # Compute min and max for each category
        min_values = {cat: min(all_final_values[cat]) for cat in categories}
        max_values = {cat: max(all_final_values[cat]) for cat in categories}
        
        # Compute the angle for each axis in the plot (in radians)
        angles = [n / float(N) * 2 * np.pi for n in range(N)]
        angles += angles[:1]  # Complete the loop by appending the first angle
        
        # Create a polar subplot for the radar chart
        fig, ax = plt.subplots(figsize=(10, 10), dpi=192, subplot_kw=dict(polar=True))
        
        # Loop over the grouped data and plot each series
        for ((_order, scenario, run_id, files_prefix), group), color in zip(self.grouped, self.colors):
            # Normalize the final value for each category
            normalized_values = []
            for cat in categories:
                val = group[cat].iloc[-1]
                norm_val = (val / max_values[cat])
                normalized_values.append(norm_val)
            normalized_values += normalized_values[:1]  # Complete the loop
            
            # Plot the normalized line for the group
            ax.plot(angles, normalized_values,
                    label=f"{files_prefix}",
                    color=color)
            ax.fill(angles, normalized_values, alpha=0.1, color=color)
        
        # Set the title and category labels
        ax.set_title(_("Total Effort Comparison"))
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels([_(cat) for cat in categories])
        
        # Set the radial axis to range from 0 to 1 (normalized scale)
        ax.set_ylim(0, 1)
        ax.set_yticks(np.linspace(0, 1, 5))
        ax.set_rlabel_position(30)
        
        # Add a legend and save the figure
        ax.legend(loc="upper right", bbox_to_anchor=(1.1, 1.1))

        outfile = f"{self.get_output_folder()}/Total_Effort_Radar.png"
        logger.info(f"Store total effort radar comparison figure at {outfile}.")
        plt.savefig(outfile, bbox_inches="tight")
        plt.clf()  # Clear the figure after saving
    
    def compare_relative_total_effort(self):
        """
        Creates a radar (spider) chart comparing effort RELATIVE to the Baseline.

        The Baseline is anchored at 1.0. 
        Values < 1.0 indicate less effort/resource usage than Baseline.
        Values > 1.0 indicate more effort/resource usage than Baseline.
        """
        # Define the categories (axes) for the radar chart
        categories = ["Subsidies", "Loans", "Cognitive resource", "Scenario fulfilment"]
        N = len(categories)
        
        # Ensure we can iterate multiple times
        grouped_data = list(self.grouped)

        # --- STEP 1: FIND BASELINE VALUES ---
        baseline_values = {}
        baseline_found = False
        
        # Search for "Baseline"
        for ((_order, _scen, _run, files_prefix), group) in grouped_data:
            if "Baseline" in files_prefix:
                for cat in categories:
                    baseline_values[cat] = group[cat].iloc[-1]
                baseline_found = True
                break
        
        # Fallback if no baseline found (use first group)
        if not baseline_found and grouped_data:
            ((_order, _scen, _run, files_prefix), group) = grouped_data[0]
            for cat in categories:
                baseline_values[cat] = group[cat].iloc[-1]
            logger.info(f"No Baseline found. Using {files_prefix} as reference (1.0).")

        # Handle potential ZeroDivision (if baseline has 0 cost)
        for cat in categories:
            if baseline_values.get(cat, 0) == 0:
                logger.warn(f"Baseline value for {cat} is 0. Normalization set to 1 to avoid error.")
                baseline_values[cat] = 1.0

        # --- STEP 2: SETUP PLOT ---
        # Compute the angle for each axis
        angles = [n / float(N) * 2 * np.pi for n in range(N)]
        angles += angles[:1]  # Complete the loop
        
        fig, ax = plt.subplots(figsize=(10, 10), dpi=192, subplot_kw=dict(polar=True))
        
        # Draw the anchor line at 1.0 (The Baseline Reference)
        ax.plot(angles, [1.0] * len(angles), color='black', linestyle='--', linewidth=1, alpha=0.5, label='_nolegend_')

        # --- STEP 3: PLOT SCENARIOS ---
        max_plotted_value = 0 # Track max to adjust limits later if needed

        for ((_order, scenario, run_id, files_prefix), group), color in zip(grouped_data, self.colors):
            
            # Calculate relative values
            relative_values = []
            for cat in categories:
                current_val = group[cat].iloc[-1]
                # Ratio: Current / Baseline
                ratio = current_val / baseline_values[cat]
                relative_values.append(ratio)
            
            # Update max tracker for scaling
            max_plotted_value = max(max_plotted_value, max(relative_values))

            # Close the loop for the plot
            relative_values += relative_values[:1]
            
            # Plot
            ax.plot(angles, relative_values,
                    label=f"{files_prefix}",
                    color=color, linewidth=2)
            
            ax.fill(angles, relative_values, alpha=0.05, color=color)
        
        # --- STEP 4: FORMATTING ---
        ax.set_title(_("Relative Effort Comparison (Baseline = 1.0)"))
        
        # Set category labels
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels([_(cat) for cat in categories])
        
        # Y-Axis Formatting
        # We need flexible limits because one scenario might be 5x the baseline.
        # We add a bit of padding (e.g., 10%) to the max value found.
        upper_limit = max(1.5, max_plotted_value * 1.1) 
        ax.set_ylim(0, upper_limit)
        
        # Draw specific grid lines for easier reading (0.5, 1.0, 1.5, etc.)
        ax.set_rlabel_position(30)
        
        # Add a legend
        ax.legend(loc="upper right", bbox_to_anchor=(1.3, 1.1))

        outfile = f"{self.get_output_folder()}/Total_Effort_Relative_Radar.png"
        logger.info(f"Store relative total effort radar figure at {outfile}.")
        plt.savefig(outfile, bbox_inches="tight")
        plt.clf() 
        plt.close(fig)
    
    def compare_heating_systems_distribution(self):
        """
        Plots the final distribution of installed heating systems.

        This method generates a grouped bar chart that shows the final count of
        each type of heating system installed across all households for each
        scenario. It provides a clear, at-a-glance comparison of the technology
        mix resulting from different simulation conditions.
        """
        if self.models_df.empty:
            print("No model data available to plot heating distributions.")
            return
    
        # Dictionary to hold the houseowners final heating distribution per group.
        hd_final_dict = {}
        
        # Loop over each unique combination using  group and color lists.
        for ((_order, scenario, run_id, files_prefix), group), color in zip(self.grouped, self.colors):
            group_reset = group.reset_index(drop=True)
            hd_dict = group_reset["Heating distribution"].iloc[-1]
            if not isinstance(hd_dict, dict):
                print(f"Heating distribution for scenario {scenario}, run_id {run_id}, files_prefix {files_prefix} is not a dictionary.")
                continue
            
            # Remove heating systems that are 0 for this combination.
            hd_dict_filtered = {_(k): v for k, v in hd_dict.items() if v != 0}
            
            # Create a label following  naming convention.
            label = f"{_(files_prefix)}"
            hd_final_dict[label] = hd_dict_filtered
    
        # Convert the collected dictionaries to a DataFrame.
        # Rows will be the group labels and columns the heating system keys.
        hd_df = pd.DataFrame.from_dict(hd_final_dict, orient="index")
        
        # Fill missing keys with 0.
        hd_df = hd_df.fillna(0)
        
        # Transpose so that the x-axis corresponds to heating system keys.
        hd_df = hd_df.transpose()
    
        # Set up the grouped bar chart.
        fig, ax = plt.subplots(figsize=(settings.eval.width,
                                        settings.eval.height), dpi=settings.eval.dpi)
        hd_df.plot(kind="bar", ax=ax, color=self.colors, width=0.8,
                   edgecolor="w", linewidth=1)
    
        if settings.eval.title_hs_distribution_final:
            ax.set_title(_("Final Heating Distribution Comparison"))
        if settings.eval.xlabel_hs_distribution_final:
            ax.set_xlabel(_("Heating System"))
        ax.set_ylabel(_("Average Count"))
        ax.set_ylim(0, hd_df.max().max()*1.2)
        plt.xticks(rotation=45, ha="right")

        # Annotate each bar with its value.
        texts = []
        hatches = np.repeat(self.hatches, len(hd_df.index))
        for patch, hatch in zip(ax.patches, hatches):
            height = patch.get_height()
            if height == 0:
                continue
            patch.set_hatch(hatch)
            texts.append(ax.text(
                patch.get_x() + patch.get_width() / 2,
                height + (ax.get_ylim()[1] * 0.01),
                f"{int(height)}",
                ha="center",
                va="bottom",
                bbox = dict(
                    facecolor='white',
                    alpha=0.5,
                    linewidth=0,
                    ),
                fontsize=9
            ))
    
        if settings.eval.use_adjust_text:
            adjust_text(texts, #arrowprops=dict(arrowstyle="->", color='b', lw=0.5),
                        expand_axes = True,
                        )
        
        if settings.eval.show_legend:
            handles, labels = ax.get_legend_handles_labels()
            ax.legend(handles = handles, labels = labels, title=_("Scenario and Run"),
                      bbox_to_anchor=(1.05, 1), loc="upper left")
    
        # Save the chart using a naming convention similar to other plots.
        outfile =  f"{self.get_output_folder()}/Heating_Distribution_Bar_Chart.png"
        logger.info(f"Store final heating distribution comparison figure at {outfile}.")
        plt.tight_layout()
        plt.savefig(outfile, bbox_inches="tight")
        plt.clf()
            

    def compare_attribute_ratings(self):
        """
        Compares agent opinions on heating systems via attribute ratings.

        This method creates detailed plots to analyse why agents prefer certain
        heating systems. For each pair of an "owned" (non-target) system and a
        "target" system, it generates a grouped bar chart.

        Each bar in the chart represents the **median difference** in agents'
        ratings for a specific attribute (e.g., 'fuel_cost', 'emissions').
        The error bars show the interquartile range (Q1 to Q3), illustrating
        the spread of opinions. This visualisation helps to identify which
        attributes drive the preference for one system over another. Plots are
        split into "aggregated" (TPB factors) and "decomposed" 
        (basic attributes) views.
        """
        if self.models_df.empty:
            logger.warn("No model data available to plot attribute ratings.")
            return
    
        labelsdf_attr = getLabels(labels_sheet="attributes", ascending=True)
        
        # Dictionary to hold the final "Attribute ratings" (differences) per scenario, run, and file prefix.
        # Each entry is expected to be a nested dictionary with structure:
        # { non_target: { target: { attribute: (q1, median, q3), ... }, ... } }
        attr_final_dict = {}
    
        # Loop over each unique combination using the grouped data.
        for ((_order, scenario, run_id, files_prefix), group), color in zip(self.grouped, self.colors):
            group_reset = group.reset_index(drop=True)
            attr_dict = group_reset["Attribute ratings"].iloc[-1]  # final row (only non-empty step)
            if not isinstance(attr_dict, dict):
                logger.warn(f"Attribute ratings for scenario {scenario}, run_id {run_id}, " + \
                            f"files_prefix {files_prefix} is not a dictionary.")
                continue
            # Create a label for this combination. Adjust naming as needed.
            label = f"{_(files_prefix)}"
            attr_final_dict[label] = attr_dict
    
        # Now, attr_final_dict is structured as:
        # { label: { owned_system: { target_system: { attribute: (q1, median, q3) } } } }
        # We now loop over each owned (non-target) system.
        all_owned = set()
        for d in attr_final_dict.values():
            all_owned.update(d.keys())
    
        # For each owned system, determine the target systems (i.e. keys inside the nested dict).
        for owned in all_owned:
            all_targets = set() # consider: sets have undefined order...
            for d in attr_final_dict.values():
                if owned in d:
                    all_targets.update(d[owned].keys())
            # For each target system, build a plot comparing its ratings with the owned system.
            for target in all_targets:
                logger.debug(f"Handle {owned} with {target}")
                # For each combination (label), if available, extract the attribute data.
                # For each attribute, we want to extract the median value and the corresponding lower (median - q1)
                # and upper (q3 - median) errors.
                plot_data = {}  # key: label, value: dict { attribute: (median, lower_err, upper_err) }
                for label, rating_dict in attr_final_dict.items():
                    if owned in rating_dict and target in rating_dict[owned]:
                        # rating_dict[owned][target] is a dict: { attribute: (q1, median, q3) }
                        attr_data = rating_dict[owned][target]
                        if attr_data:
                            processed = {}
                            for attr, (q1, med, q3, num_cases) in attr_data.items():
                                lower_err = med - q1
                                upper_err = q3 - med
                                processed[_(attr)] = (med, lower_err, upper_err, num_cases)
                            plot_data[label] = processed
    
                # If no data exists for this combination, skip plotting.
                if not plot_data:
                    continue
    
                # Build DataFrames for medians and error values.
                # Rows: attributes, Columns: labels (combinations)
                attributes = {attr for data in plot_data.values() for attr in data.keys()}
                attributes = sorted(attributes, key=dict(zip(labelsdf_attr.value, labelsdf_attr.order)).get)
                # dict(zip(labelsdf["label"], range(len(labelsdf))))
                
                medians_df = pd.DataFrame(index=attributes, columns=plot_data.keys())
                lower_err_df = pd.DataFrame(index=attributes, columns=plot_data.keys())
                upper_err_df = pd.DataFrame(index=attributes, columns=plot_data.keys())
                num_cases_df = pd.DataFrame(index=attributes, columns=plot_data.keys())
    
                for label, data in plot_data.items():
                    for attr in attributes:
                        if attr in data:
                            medians_df.loc[attr, label] = data[attr][0]
                            lower_err_df.loc[attr, label] = data[attr][1]
                            upper_err_df.loc[attr, label] = data[attr][2]
                            num_cases_df.loc[attr, label] =  data[attr][3]
                        else:
                            medians_df.loc[attr, label] = 0
                            lower_err_df.loc[attr, label] = 0
                            upper_err_df.loc[attr, label] = 0
                            num_cases_df.loc[attr, label] = 0
    
                # Ensure numeric types.
                medians_df = medians_df.astype(float)
                lower_err_df = lower_err_df.astype(float)
                upper_err_df = upper_err_df.astype(float)
                
                # -------------------------------
                # Split attributes into two groups:
                influential_keys = {"Attitude", "Social norm", "Behavioural control"}
                influential_attrs = [attr for attr in attributes if attr in influential_keys]
                lesser_attrs = [attr for attr in attributes if attr not in influential_keys]
                
                # For each attribute group, create a separate plot.
                for group_name, group_attrs in [("aggregate", influential_attrs), ("decomposed", lesser_attrs)]:
                    # Skip if the group is empty.
                    if not group_attrs:
                        continue
                    
                    # Subset the DataFrames to only include the attributes in the current group.
                    medians_df_group = medians_df.loc[group_attrs]
                    lower_err_df_group = lower_err_df.loc[group_attrs]
                    upper_err_df_group = upper_err_df.loc[group_attrs]
                    num_cases_df_group = num_cases_df.loc[group_attrs]
    
                    # -------------------------------
                    # Plotting: Bar chart with error bars for the group.
                    # -------------------------------
                    fig, ax = plt.subplots(figsize=(settings.eval.width,
                                                    settings.eval.height), dpi=settings.eval.dpi)
                    x = np.arange(len(group_attrs))  # x positions for the group attributes
                    total_width = 0.8  # total width for all bars at one attribute
                    num_labels = len(medians_df_group.columns)
                    bar_width = total_width / num_labels
                    # Compute offsets so that the bars for different combinations appear side-by-side.
                    offsets = np.linspace(-total_width/2 + bar_width/2, total_width/2 - bar_width/2, num_labels)
    
                    labelsdf_prefix = getLabels(labels_sheet="files_prefix", ascending=True)
                    colors = labelsdf_prefix[labelsdf_prefix["label"].isin(medians_df_group.columns)]["colour"].tolist()
                    hatches = [None if hatch=="None" else hatch for hatch in 
                       labelsdf_prefix[labelsdf_prefix["label"].isin(medians_df_group.columns)]["hatch"].tolist()]
    
                    for (i, label), color, hatch in zip(enumerate(medians_df_group.columns), colors, hatches):
                        medians = medians_df_group[label].values
                        lower_err = lower_err_df_group[label].values
                        upper_err = upper_err_df_group[label].values
                        # yerr is a 2D array: [lower errors, upper errors]
                        yerr = [lower_err, upper_err]
                        num_cases_label = (f" [{num_cases_df_group[label].mean():.1f}]" 
                            if (None not in num_cases_df_group[label]) else "")
                        ax.bar(x + offsets[i], medians, width=bar_width, label=label + 
                                num_cases_label, yerr=yerr, capsize=5,
                               color=color, hatch=hatch, edgecolor="w", linewidth=1)
    
                    ax.set_xticks(x)
                    ax.set_xticklabels(group_attrs, rotation=45, ha="right")
                    ax.set_ylabel(_("Difference Value"))
                    # Append the group name to the title.
                    title_suffix = _(" (Aggregated)") if group_name == "aggregate" else _(" (Decomposed)")
                    
                    if settings.eval.title_attributes:
                        ax.set_title(_("Attribute Differences for ") + _(target) + _(" vs ") + _(owned) + title_suffix, pad=20)
                    ax.legend(title=_("Scenario/Run"), bbox_to_anchor=(1.05, 1), loc="upper left")
    
                    ax.set_ylim(-1, 1)
    
                    ax.axhline(0, color="black", linewidth=1, linestyle="--")
                                    
                    # Save the plot.
                    if not os.path.exists(f"{self.get_output_folder()}/attribute_comparison"):
                        os.makedirs(f"{self.get_output_folder()}/attribute_comparison")
                    output_path = f"{self.get_output_folder()}/attribute_comparison/Attribute_Differences_{target}_vs_{owned}_{group_name}.png"
                    logger.info(f"Store attribute comparison figure at {output_path}.")
                    plt.savefig(output_path, bbox_inches="tight")
                    plt.clf()
                    plt.close(fig)

    def combine_attribute_ratings(self, dict_list):
        """
        Averages nested attribute rating dictionaries from multiple runs.

        This is a helper function that takes a list of the complex, nested
        `Attribute ratings` dictionaries (one from each random seed) and computes
        the element-wise mean of the quartile tuples `(q1, median, q3)`. This
        produces a single, averaged dictionary representing the typical agent
        opinions for a given scenario.

        Parameters
        ----------
        dict_list : list of dict
            A list where each element is a nested dictionary of attribute ratings
            from a single simulation run.

        Returns
        -------
        dict
            A single nested dictionary with the averaged quartile values.
        """
        result = {}
        if not dict_list:
            return result
        # Assume all dictionaries share the same keys
        for non_target in dict_list[0]:
            result[non_target] = {}
            for target in dict_list[0][non_target]:
                # If for some reason the inner dict is empty, keep it empty.
                if not dict_list[0][non_target][target]:
                    result[non_target][target] = {}
                    continue
                result[non_target][target] = {}
                for attr, tup in dict_list[0][non_target][target].items():
                    if attr != "num_cases":
                        q1_list = []
                        q2_list = []
                        q3_list = []
                        num_cases_list = []
                        for d in dict_list:
                            # Check if the dictionary for (non_target, target) is non-empty,
                            # and that the attribute exists.
                            if non_target in d and target in d[non_target]:
                                t = d[non_target][target].get(attr)
                                if t is not None:
                                    q1_list.append(t[0])
                                    q2_list.append(t[1])
                                    q3_list.append(t[2])
                                    num_cases_list.append(d[non_target][target].get("num_cases"))
                        if q1_list:
                            result[non_target][target][attr] = (
                                sum(q1_list) / len(q1_list),
                                sum(q2_list) / len(q2_list),
                                sum(q3_list) / len(q3_list),
                                (sum(num_cases_list) / len(num_cases_list)
                                 if None not in num_cases_list else None),
                            )
                        else:
                            result[non_target][target][attr] = ()
        return result

    def make_output_table(self):
        """
        Exports key final simulation results to an Excel file.

        This method extracts the final values for critical metrics like
        'Scenario fulfilment', 'Emissions', and 'LCOH' for each scenario and
        compiles them into a summary table. The table is then saved as an
        Excel file for easy reporting and external analysis.
        """
        if not self.grouped:
            print("Grouped model data is empty")
        else:
            output_path = f"{get_output_path(runid=settings.main.run_id, subfolder='tables')}/{self.folder_suffix}"
            if not os.path.exists(output_path):
                os.makedirs(output_path)
    
            rows = []
    
            for name, group in self.grouped:
                group_name = name[-1] if isinstance(name, tuple) else name
    
                # Extract values from the last row of the group
                scenario_fulfilment = group['Scenario fulfilment'].iloc[-1]
                emissions = group['Emissions'].iloc[-1] * 514 / 1000000 #To convert to total tonns
                total_expenses = group['Total expenses'].iloc[-1]
    
                rows.append({
                    'Name': group_name,
                    'Scenario fulfilment': scenario_fulfilment,
                    'Emissions': emissions,
                    'LCOH': total_expenses
                })
    
            # Create DataFrame and export
            result_df = pd.DataFrame(rows)
            result_df.to_excel(f"{output_path}/output_table_DT2.xlsx", index=False)
            
    def to_csv(self):
        """
        Saves the aggregated agent and model DataFrames to CSV files.

        This function provides a way to export the main processed DataFrames
        (`self.agents_df` and `self.models_df`) into CSV format for further
        analysis in other tools or for archival purposes.
        """
        agent_filepath = f"{get_output_path(runid=settings.main.run_id, subfolder='tables')}/{self.folder_suffix}/Aggregated_agent_results.csv"
        if not os.path.exists(agent_filepath):
            os.makedirs(agent_filepath)
        self.agents_df.to_csv(agent_filepath, index=True)
        model_filepath = f"{get_output_path(runid=settings.main.run_id, subfolder='tables')}/{self.folder_suffix}/Aggregated_model_results.csv"
        if not os.path.exists(model_filepath):
            os.makedirs(model_filepath)
        self.models_df.to_csv(model_filepath, index=True)
        

if __name__ == "__main__":
    plotter = Scenario_comparator() # pass rund_ids
    plotter.scenario_fulfilment_comp(
        colors = ["xkcd:orange", "xkcd:yellow", "xkcd:grey", "xkcd:blue"], # for energy costs / CO2 tax
        #colors = ["xkcd:yellow", "xkcd:grey", "xkcd:orange", "xkcd:blue"], # for installation costs
        reverse_columns = True
    )
        